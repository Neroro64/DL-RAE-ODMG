{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, time\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "import json as js\n",
    "import _pickle as pickle\n",
    "import bz2\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from collections import OrderedDict\n",
    "from cytoolz import sliding_window, accumulate\n",
    "import pytorch_lightning as pl\n",
    "from operator import add\n",
    "from tabulate import tabulate\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../rig_agnostic_encoding\")\n",
    "sys.path.append(\"../rig_agnostic_encoding/models\")\n",
    "sys.path.append(\"../rig_agnostic_encoding/functions\")\n",
    "import func\n",
    "# from MLP_withLabel import MLP_withLabel\n",
    "# from MLP import MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/nuoc/Documents/MEX/data\"\n",
    "MODEL_PATH = \"/home/nuoc/Documents/MEX/models\"\n",
    "RESULTS_PATH = \"/home/nuoc/Documents/MEX/results\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class MLP_withLabel(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, dimensions:list=None, extra_feature_len:int=0,\n",
    "                 train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name:str=\"model\", load=False,\n",
    "                 single_module:int=0):\n",
    "\n",
    "        super(MLP_withLabel, self).__init__()\n",
    "        self.name = name\n",
    "        self.dimensions = dimensions\n",
    "        self.keep_prob = keep_prob\n",
    "        self.single_module = single_module\n",
    "        self.extra_feature_len = extra_feature_len\n",
    "        self.act = nn.ELU\n",
    "        self.k = 0\n",
    "        if load:\n",
    "            self.build()\n",
    "        else:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.k = config[\"k\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.act = config[\"activation\"]\n",
    "            self.loss_fn = config[\"ae_loss_fn\"]\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "            self.dimensions = [self.dimensions[0]-extra_feature_len, self.hidden_dim, self.k]\n",
    "            self.train_set = train_set\n",
    "            self.val_set = val_set\n",
    "            self.test_set = test_set\n",
    "\n",
    "            self.best_val_loss = np.inf\n",
    "\n",
    "        self.build()\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "        if self.single_module == -1 or self.single_module == 0:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.encoder = nn.Sequential()\n",
    "\n",
    "        if self.single_module == 0 or self.single_module == 1:\n",
    "            layers = []\n",
    "            layer_sizes[-1] = (layer_sizes[-1][0], layer_sizes[-1][1] + self.extra_feature_len)\n",
    "            for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decode(*self.encode(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        _x, label = x[:, :-self.extra_feature_len], x[:, -self.extra_feature_len:]\n",
    "        h = self.encoder(_x)\n",
    "        return h, label\n",
    "\n",
    "    def decode(self, h, label):\n",
    "        hr = torch.cat((h, label), dim=1)\n",
    "        return self.decoder(hr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(best_val_loss=self.best_val_loss.cpu().numpy())\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"k\":self.k, \"dimensions\":self.dimensions,\"keep_prob\":self.keep_prob, \"name\":self.name,\n",
    "                 \"extra_feature_len\" : self.extra_feature_len,\n",
    "                 \"encoder\":self.encoder.state_dict(),\n",
    "                 \"decoder\":self.decoder.state_dict()}\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".\"+str(self.k)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MLP_withLabel(name=obj[\"name\"], dimensions=obj[\"dimensions\"], extra_feature_len=obj[\"extra_feature_len\"], keep_prob=obj[\"keep_prob\"], load=True)\n",
    "        model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, dimensions:list=None,\n",
    "                 train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name:str=\"model\", load=False,\n",
    "                 single_module:int=0):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        self.name = name\n",
    "        self.dimensions = dimensions\n",
    "        self.keep_prob = keep_prob\n",
    "        self.single_module = single_module\n",
    "        self.act = nn.ELU\n",
    "        self.k = 0\n",
    "        if load:\n",
    "            self.build()\n",
    "        else:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.k = config[\"k\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.act = config[\"activation\"]\n",
    "            self.loss_fn = config[\"loss_fn\"]\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "            self.dimensions = dimensions + [self.hidden_dim, self.k]\n",
    "            self.train_set = train_set\n",
    "            self.val_set = val_set\n",
    "            self.test_set = test_set\n",
    "\n",
    "            self.best_val_loss = np.inf\n",
    "\n",
    "            self.build()\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "        if self.single_module == -1 or self.single_module == 0:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.encoder = nn.Sequential()\n",
    "\n",
    "        if self.single_module == 0 or self.single_module == 1:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(best_val_loss=self.best_val_loss.cpu().numpy())\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"k\":self.k, \"dimensions\":self.dimensions,\"keep_prob\":self.keep_prob, \"name\":self.name,\n",
    "                 \"encoder\":self.encoder.state_dict(),\n",
    "                 \"decoder\":self.decoder.state_dict()}\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".\"+str(self.k)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MLP(name=obj[\"name\"], dimensions=obj[\"dimensions\"], keep_prob=obj[\"keep_prob\"], load=True)\n",
    "        model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class MoE(nn.Module):\n",
    "    def __init__(self, config=None, dimensions=None, phase_input_dim:int=0, gate_size=0, name=\"model\", load=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.phase_input_dim = phase_input_dim\n",
    "        self.dimensions = dimensions\n",
    "        self.act_fn = nn.ELU\n",
    "        self.name = name\n",
    "        self.config=config\n",
    "        self.gate_size=gate_size\n",
    "        if not load:\n",
    "            self.k_experts = config[\"k_experts\"]\n",
    "            self.gate_size = config[\"gate_size\"]\n",
    "            self.keep_prob = config[\"keep_prob\"]\n",
    "            self.dimensions = [self.dimensions[0], config[\"hidden_dim\"], config[\"hidden_dim\"], self.dimensions[-1]]\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        self.build()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(phase_input_dim, self.gate_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.gate_size, self.gate_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.gate_size, self.k_experts)\n",
    "        )\n",
    "        self.init_params()\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor, phase) -> torch.Tensor:\n",
    "        coefficients = F.softmax(self.gate(phase), dim=1)\n",
    "\n",
    "        layer_out = x\n",
    "        for (weight, bias, activation) in self.layers:\n",
    "            if weight is None:\n",
    "                layer_out = activation(layer_out, p=self.keep_prob)\n",
    "            else:\n",
    "                flat_weight = weight.flatten(start_dim=1, end_dim=2)\n",
    "                mixed_weight = torch.matmul(coefficients, flat_weight).view(\n",
    "                    coefficients.shape[0], *weight.shape[1:3]\n",
    "                )\n",
    "\n",
    "                input = layer_out.unsqueeze(1)\n",
    "                mixed_bias = torch.matmul(coefficients, bias).unsqueeze(1)\n",
    "                out = torch.baddbmm(mixed_bias, input, mixed_weight).squeeze(1)\n",
    "                layer_out = activation(out) if activation is not None else out\n",
    "\n",
    "        return layer_out\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        for i, size in enumerate(zip(self.dimensions[0:], self.dimensions[1:])):\n",
    "            if i < len(self.dimensions) - 2:\n",
    "                layers.append(\n",
    "                    (\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[0], size[1])),\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[1])),\n",
    "                        self.act_fn()\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                layers.append(\n",
    "                    (\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[0], size[1])),\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[1])),\n",
    "                        None\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if self.keep_prob > 0:\n",
    "                layers.append((None, None, F.dropout))\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "    def init_params(self):\n",
    "        for i, (w, b, _) in enumerate(self.layers):\n",
    "            if w is None:\n",
    "                continue\n",
    "\n",
    "            i = str(i)\n",
    "            torch.nn.init.kaiming_uniform_(w)\n",
    "            b.data.fill_(0.01)\n",
    "            self.register_parameter(\"w\" + i, w)\n",
    "            self.register_parameter(\"b\" + i, b)\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"dimensions\":self.dimensions,\n",
    "                 \"name\":self.name,\n",
    "                 \"gate\":self.gate.state_dict(), \"phase_input_dim\":self.phase_input_dim,\n",
    "                 \"generationNetwork\":self.state_dict(),\n",
    "                 \"gate_size\":self.gate_size,\n",
    "                 }\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MoE(name=obj[\"name\"], dimensions=obj[\"dimensions\"], gate_size=obj[\"gate_size\"],\n",
    "                    phase_input_dim=obj[\"phase_input_dim\"])\n",
    "        model.gate.load_state_dict(obj[\"gate\"])\n",
    "        model.load_state_dict(obj[\"generationNetwork\"])\n",
    "        return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class MotionGenerationModel(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, pose_autoencoder=None, cost_input_dimension=None,\n",
    "                 input_slicers:list=None, output_slicers:list=None, train_set=None, val_set=None, name=\"model\", load=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if not load:\n",
    "            self.pose_autoencoder = pose_autoencoder # start with 3\n",
    "            cost_hidden_dim = config[\"cost_hidden_dim\"]\n",
    "            self.cost_encoder = MLP(dimensions=[cost_input_dimension, cost_hidden_dim, cost_hidden_dim],\n",
    "                                    name=\"CostEncoder\", load=True, single_module=-1)\n",
    "\n",
    "\n",
    "            phase_dim = input_slicers[0]\n",
    "            moe_input_dim = pose_autoencoder.dimensions[-1] + cost_hidden_dim\n",
    "            moe_output_dim = pose_autoencoder.dimensions[-1] + pose_autoencoder.extra_feature_len + phase_dim*2\n",
    "            self.generationModel =  MoE(config=config, dimensions=[moe_input_dim, moe_output_dim], phase_input_dim=phase_dim,\n",
    "                                        name=\"MixtureOfExperts\")\n",
    "\n",
    "            self.in_slices = [0] + list(accumulate(add, input_slicers))\n",
    "            self.out_slices = [0] + list(accumulate(add, output_slicers))\n",
    "\n",
    "            self.config=config\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.loss_fn = config[\"loss_fn\"]\n",
    "            self.window_size = config[\"window_size\"]\n",
    "            self.autoregress_prob = config[\"autoregress_prob\"]\n",
    "            self.autoregress_inc = config[\"autoregress_inc\"]\n",
    "            self.best_val_loss = np.inf\n",
    "            self.phase_smooth_factor = 0.9\n",
    "\n",
    "        self.train_set = train_set\n",
    "        self.val_set = val_set\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=torch.squeeze(x,dim=0)\n",
    "        x_tensors = [x[:, d0:d1] for d0, d1 in zip(self.in_slices[:-1], self.in_slices[1:])]\n",
    "        pose_h, pose_label = self.pose_autoencoder.encode(x_tensors[1])\n",
    "        embedding = torch.cat([pose_h, self.cost_encoder(x_tensors[2])], dim=1)\n",
    "\n",
    "        out = self.generationModel(embedding, x_tensors[0])\n",
    "        out_tensors = [out[:, d0:d1] for d0, d1 in zip(self.out_slices[:-1], self.out_slices[1:])] # phase, phase_update, pose\n",
    "\n",
    "        phase = self.update_phase(x_tensors[0], out_tensors[0], out_tensors[1]) # phase_0, phase_1, phase_update\n",
    "        new_pose = self.pose_autoencoder.decode(out_tensors[2], pose_label)\n",
    "        return torch.cat([phase, new_pose], dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # sequences = sliding_window(self.window_size, x)\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "        self.log(\"ptl/val_loss\", loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint()\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir=MODEL_PATH):\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        loss = self.best_val_loss.cpu().numpy()\n",
    "\n",
    "        pose_autoencoder_path = self.pose_autoencoder.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "        cost_encoder_path = self.cost_encoder.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "        generationModel_path = self.generationModel.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "\n",
    "        model = {\"name\":self.name,\n",
    "                 \"pose_autoencoder_path\":pose_autoencoder_path,\n",
    "                 \"cost_encoder_path\": cost_encoder_path,\n",
    "                 \"motionGenerationModelPath\":generationModel_path,\n",
    "                 \"in_slices\":self.in_slices,\n",
    "                 \"out_slices\":self.out_slices,\n",
    "                 }\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        with bz2.BZ2File(os.path.join(path,\n",
    "                                      str(loss)+\".pbz2\"), \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filename, pose_ae_model, cost_encoder_model, generation_model):\n",
    "        with bz2.BZ2File(filename, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        pose_autoencoder = pose_ae_model.load_checkpoint(obj[\"pose_autoencoder_path\"])\n",
    "        cost_encoder = cost_encoder_model.load_checkpoint(obj[\"cost_encoder_path\"])\n",
    "        generationModel = generation_model.load_checkpoint(obj[\"motionGenerationModelPath\"])\n",
    "        model = MotionGenerationModel(name=obj[\"name\"])\n",
    "        model.pose_autoencoder = pose_autoencoder\n",
    "        model.cost_encoder = cost_encoder\n",
    "        model.generationModel = generationModel\n",
    "        model.in_slices = obj[\"in_slices\"]\n",
    "        model.out_slices = obj[\"out_slices\"]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def update_phase(self, p1, p2, p_delta):\n",
    "        return self.phase_smooth_factor * p2 + (1-self.phase_smooth_factor)*(p1+p_delta)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "data_path = \"/home/nuoc/Documents/MEX/data/ONE_R2-default-One.pbz2\"\n",
    "\n",
    "pose_features = [\"pos\", \"rotMat\", \"velocity\", \"isLeft\", \"chainPos\", \"geoDistanceNormalised\"]\n",
    "cost_features = [\"posCost\", \"rotCost\", \"targetPosition\", \"targetRotation\"]\n",
    "phase_features = [\"phase_vec\", \"contact\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-26ad492c535a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-31-26ad492c535a>\u001B[0m in \u001B[0;36mload\u001B[0;34m(file_path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mbz2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBZ2File\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m         \u001B[0mobj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/bz2.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    202\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_can_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 204\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadinto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    205\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/_compression.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m     66\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mreadinto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mmemoryview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mview\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mview\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"B\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mbyte_view\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbyte_view\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     69\u001B[0m             \u001B[0mbyte_view\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/_compression.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    101\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m                     \u001B[0mrawblock\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mb\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_decompressor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecompress\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrawblock\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def load(file_path):\n",
    "    with bz2.BZ2File(file_path, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "        return obj\n",
    "\n",
    "data = load(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_tensors = []\n",
    "\n",
    "data_dims = []\n",
    "feature_list = []\n",
    "\n",
    "first_row = True\n",
    "for clip in data:\n",
    "    d = pickle.loads(clip)\n",
    "    sequence = []\n",
    "    for frame in d[\"frames\"]:\n",
    "        row_vec = []\n",
    "        for feature in phase_features:\n",
    "            if feature == \"contact\":\n",
    "                row_vec.append(np.asarray([jo[\"contact\"] for jo in frame if jo[\"key\"]], dtype=np.float32))\n",
    "            elif feature == \"phase_vec\":\n",
    "                sin = np.asarray([jo[\"phase_vec\"] for jo in frame if jo[\"key\"]])\n",
    "                vel = np.concatenate([jo[\"velocity\"] for jo in frame if jo[\"key\"]])\n",
    "                vel = np.reshape(vel, (3,-1))\n",
    "                vel = np.sqrt(np.sum(vel**2, axis=0))\n",
    "                vel[vel==0] = 1\n",
    "                cos = np.cos(np.arcsin(sin/vel)) * vel\n",
    "                row_vec.append(np.concatenate([np.asarray([sin[i], cos[i]]) for i in range(len(sin))]))\n",
    "            else:\n",
    "                row_vec.append(np.asarray([jo[feature] for jo in frame if jo[\"key\"]]))\n",
    "\n",
    "            if first_row:\n",
    "                data_dims.append(row_vec[-1].shape)\n",
    "                feature_list.append(feature)\n",
    "        for feature in pose_features:\n",
    "            if feature==\"rotMat\":\n",
    "                row_vec.append(np.concatenate([jo[\"rotMat\"].ravel() for jo in frame]))\n",
    "            elif feature == \"isLeft\" or feature == \"chainPos\" or feature == \"geoDistanceNormalised\":\n",
    "                row_vec.append(np.concatenate([[jo[feature]] for jo in frame]))\n",
    "            else:\n",
    "                row_vec.append(np.concatenate([jo[feature] for jo in frame]))\n",
    "\n",
    "            if first_row:\n",
    "                data_dims.append(row_vec[-1].shape)\n",
    "                feature_list.append(feature)\n",
    "        for feature in cost_features:\n",
    "            if feature == \"targetRotation\":\n",
    "                row_vec.append(np.concatenate([jo[feature].ravel() for jo in frame if jo[\"key\"]]))\n",
    "            else:\n",
    "                row_vec.append(np.concatenate([jo[feature] for jo in frame if jo[\"key\"]]))\n",
    "\n",
    "            if first_row:\n",
    "                data_dims.append(row_vec[-1].shape)\n",
    "                feature_list.append(feature)\n",
    "        if first_row: first_row = False\n",
    "        sequence.append(np.concatenate(row_vec))\n",
    "    data_tensors.append(np.vstack(sequence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    return (x-y).pow(2).mean(dim=(0,-1)).sum()\n",
    "def normalise(x):\n",
    "    std = torch.std(x, dim=0)\n",
    "    std[std==0] = 1\n",
    "    return (x-torch.mean(x)) / std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_feature_len = 21 * 3\n",
    "n_phase_features = len(phase_features)\n",
    "n_pose_features = len(pose_features)\n",
    "phase_dim = np.sum(data_dims[0:n_phase_features])\n",
    "pose_dim = np.sum(data_dims[n_phase_features:n_phase_features+n_pose_features])\n",
    "cost_dim = np.sum(data_dims[n_phase_features+n_pose_features:])\n",
    "\n",
    "table = [feature_list, data_dims]\n",
    "print(tabulate(table))\n",
    "print(\"phase dim: \",phase_dim)\n",
    "print(\"pose dim: \", pose_dim)\n",
    "print(\"cost dim: \", cost_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_tensors = [normalise(torch.from_numpy(clip[:-1]).float()) for clip in data_tensors]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_tensors = torch.stack([clip[:-1] for clip in data_tensors])\n",
    "y_tensors = torch.stack([clip[1:][:, :-(cost_dim+extra_feature_len)] for clip in data_tensors])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(x_tensors), x_tensors[0].shape)\n",
    "print(len(y_tensors), y_tensors[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_tensors, y_tensors)\n",
    "N = len(x_tensors)\n",
    "\n",
    "train_ratio = int(.7*N)\n",
    "val_ratio = int((N-train_ratio) / 2.0)\n",
    "train_set, val_set, test_set = random_split(dataset, [train_ratio, val_ratio, val_ratio], generator=torch.Generator().manual_seed(2021))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_dim = phase_dim + pose_dim + cost_dim\n",
    "output_dim = phase_dim + pose_dim-extra_feature_len\n",
    "print(input_dim)\n",
    "print(output_dim)\n",
    "\n",
    "config = {\n",
    "    \"k_experts\":tune.choice([1, 2, 4, 8, 10]),\n",
    "    \"gate_size\":tune.choice([16, 32, 64, 128]),\n",
    "    \"keep_prob\":tune.choice([.2, .3]),\n",
    "    \"hidden_dim\":tune.choice([16, 32, 64, 128]),\n",
    "    \"cost_hidden_dim\" : tune.choice([16, 32, 64, 128]),\n",
    "    \"batch_size\":tune.choice([1]),\n",
    "    \"lr\":tune.loguniform(1e-3, 1e-7),\n",
    "    \"loss_fn\":tune.choice([loss_fn]),\n",
    "    \"window_size\":tune.choice([1]),\n",
    "    \"autoregress_prob\" : tune.choice([.2]),\n",
    "    \"autoregress_inc\" : tune.choice([.1])\n",
    "}\n",
    "\n",
    "config_moe = {\n",
    "    \"k_experts\":1,\n",
    "    \"gate_size\":64,\n",
    "    \"keep_prob\":.3,\n",
    "    \"hidden_dim\":[64,64],\n",
    "    \"batch_size\":1,\n",
    "    \"lr\":1e-3,\n",
    "    \"loss_fn\":loss_fn,\n",
    "    \"window_size\":1,\n",
    "    \"autoregress_prob\" : .2,\n",
    "    \"autoregress_inc\" : .2\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = MotionGenerationModel(config=config, pose_autoencoder=pose_encoder, cost_encoder=cost_encoder,\n",
    "#                               generationModel=moe,\n",
    "#                               input_slicers=[phase_dim, pose_dim, cost_dim],\n",
    "#                               output_slicers=[phase_dim, phase_dim, pose_encoder_out_dim],\n",
    "#                               train_set=train_set, val_set=val_set, name=\"Test\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimizer = model.configure_optimizers()\n",
    "# for i in range(Epochs):\n",
    "#     for x, y in train_set:\n",
    "#         out = model(x)\n",
    "#         loss = loss_fn(out, y)\n",
    "#\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         j = 0\n",
    "#         val_loss = 0\n",
    "#         for x,y in val_set:\n",
    "#             out = model(x)\n",
    "#             loss = loss_fn(out, y)\n",
    "#             val_loss += loss\n",
    "#             j+=1\n",
    "#         val_loss /= j\n",
    "#         print(\"EPOCH: \", i, \" Val loss: \", val_loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tuning(config=None, MODEL=None, pose_autoencoder=None, cost_dim=None,\n",
    "          input_slices=None, output_slices=None,\n",
    "          train_set=None, val_set=None, num_epochs=300, model_name=\"model\"):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,\n",
    "        gpus=1,\n",
    "        logger=TensorBoardLogger(save_dir=\"logs/\", name=model_name, version=\"0.0\"),\n",
    "        progress_bar_refresh_rate=5,\n",
    "        callbacks=[\n",
    "            TuneReportCallback({\"loss\": \"avg_val_loss\", }, on=\"validation_end\"),\n",
    "            EarlyStopping(monitor=\"avg_val_loss\")\n",
    "        ],\n",
    "        precision=16,\n",
    "    )\n",
    "    model = MODEL(config=config, pose_autoencoder=pose_autoencoder, cost_input_dimension=cost_dim,\n",
    "                              input_slicers=input_slices, output_slicers=output_slices,\n",
    "                              train_set=train_set, val_set=val_set, name=\"Test\")\n",
    "\n",
    "    trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Epochs = 300\n",
    "Samples = 20\n",
    "ModelName=\"MoE_Test\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pose_autoencoder = MLP_withLabel.load_checkpoint(\"/home/nuoc/Documents/MEX/models/MLP4_withLabel_best/M3/0.00324857.512.pbz2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pose_encoder_out_dim = pose_autoencoder.dimensions[-1]\n",
    "pose_decoder_in_dim = pose_autoencoder.dimensions[-1] + extra_feature_len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t = Epochs, grace_period=1, reduction_factor=2)\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=[\"k\", \"lr\", \"batch_size\", \"loss_fn\"],\n",
    "    metric_columns=[\"loss\", \"training_iteration\"],\n",
    "    max_error_rows=5,\n",
    "    max_progress_rows=5,\n",
    "    max_report_frequency=10)\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(\n",
    "        tuning,\n",
    "        MODEL=MotionGenerationModel,\n",
    "        pose_autoencoder=pose_autoencoder,\n",
    "        cost_dim = cost_dim,\n",
    "        input_slices=[phase_dim, pose_dim, cost_dim],\n",
    "        output_slices=[phase_dim, phase_dim, pose_encoder_out_dim],\n",
    "        train_set=train_set, val_set=val_set,\n",
    "        num_epochs=Epochs,\n",
    "        model_name=ModelName\n",
    "    ),\n",
    "    resources_per_trial= {\"cpu\":1, \"gpu\":1},\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    config=config,\n",
    "    num_samples=Samples,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=ModelName,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Done\")\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "print(\"Best achieved loss was: \", analysis.best_result)\n",
    "print(\"-\"*70)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}