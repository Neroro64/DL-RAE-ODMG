{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"motion_generation\")\n",
    "sys.path.append(\"rig_agnostic_encoding/functions\")\n",
    "sys.path.append(\"rig_agnostic_encoding/models\")\n",
    "\n",
    "from motion_generation.MoE import MoE\n",
    "import motion_generation\n",
    "from motion_generation.GRU import GRU\n",
    "from motion_generation.LSTM import LSTM\n",
    "from motion_generation.MotionGeneration import MotionGenerationModel\n",
    "from motion_generation.MotionGeneration_v2 import MotionGenerationModel as MotionGenerationModel_v2\n",
    "from motion_generation.MotionGeneration_v3 import MotionGenerationModel as MotionGenerationModel_v3\n",
    "from motion_generation.MotionGenerationRNN import MotionGenerationModelRNN\n",
    "from motion_generation.MotionGenerationBatch import MotionGenerationModelBatch\n",
    "from rig_agnostic_encoding.models.MLP import MLP\n",
    "from rig_agnostic_encoding.models.DEC import DEC\n",
    "from rig_agnostic_encoding.models.MLP_MIX import MLP_MIX\n",
    "from rig_agnostic_encoding.models.VAE import VAE\n",
    "from rig_agnostic_encoding.functions.DataProcessingFunctions import clean_checkpoints\n",
    "from GlobalSettings import MODEL_PATH\n",
    "import bz2\n",
    "from cytoolz import concat\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import func as F\n",
    "import _pickle as pickle\n",
    "import json as js\n",
    "import importlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"hidden_dim\": 512,\n",
    "    \"k\": 512,\n",
    "    \"lr\": 1e-4,\n",
    "    \"batch_size\": 8,\n",
    "    \"keep_prob\": .2,\n",
    "    \"loss_fn\":torch.nn.functional.mse_loss,\n",
    "    \"optimizer\":torch.optim.AdamW,\n",
    "    \"scheduler\":torch.optim.lr_scheduler.StepLR,\n",
    "    \"scheduler_param\": {\"step_size\":80, \"gamma\":.9},\n",
    "    \"basis_func\":\"gaussian\",\n",
    "    \"n_centroid\":64,\n",
    "    \"k_experts\": 4,\n",
    "    \"gate_size\": 128,\n",
    "    \"g_hidden_dim\": 512,\n",
    "    \"num_layers\": 4,\n",
    "    \"autoregress_prob\":.5,\n",
    "    \"autoregress_inc\":0,\n",
    "    \"autoregress_ep\":50,\n",
    "    \"autoregress_max_prob\":.5,\n",
    "    \"cost_hidden_dim\":128,\n",
    "    \"seq_len\":13,\n",
    "    \"device\":\"cuda\"\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "def getFilesNames(file_paths, data_path, MAX_FILES=-1):\n",
    "    for dname, dirs, files in os.walk(data_path):\n",
    "        for i, file in enumerate(files):\n",
    "            file_paths.append(os.path.join(dname, file))\n",
    "            if MAX_FILES > 0 and i >= MAX_FILES:\n",
    "                break\n",
    "    return file_paths\n",
    "data_path = \"/home/nuoc/Documents/MEX/data/data/Dataset_R1_Two_1\"\n",
    "data_path2 = \"/home/nuoc/Documents/MEX/data/data/Dataset_R2_Two_1\"\n",
    "data_path3 = \"/home/nuoc/Documents/MEX/data/data/Dataset_R3_Two_1\"\n",
    "data_path4 = \"/home/nuoc/Documents/MEX/data/data/Dataset_R4_Two_1\"\n",
    "file_paths = getFilesNames([],data_path)\n",
    "file_paths2 = getFilesNames([],data_path2)\n",
    "file_paths3 = getFilesNames([],data_path3)\n",
    "file_paths4 = getFilesNames([],data_path4)\n",
    "\n",
    "print(len(file_paths))\n",
    "print(len(file_paths2))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "phase_features = [\"phase_vec_l2\"]\n",
    "pose_features = [\"pos\", \"rotMat2\", \"velocity\"]\n",
    "cost_features = [\"posCost\", \"rotCost\"]\n",
    "target_features = [\"targetPosition\", \"targetRotation\"]\n",
    "features = phase_features + pose_features + cost_features + target_features\n",
    "clips = []\n",
    "feature_dims = {}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 09:37:39,179\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2021-05-08 09:37:59,909\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2021-05-08 09:38:20,609\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2021-05-08 09:38:41,224\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "data = F.process_data_multithread(file_paths, features)\n",
    "data2 = F.process_data_multithread(file_paths2, features)\n",
    "data3 = F.process_data_multithread(file_paths3, features)\n",
    "data4 = F.process_data_multithread(file_paths4, features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "feature_dims = data[0][1]\n",
    "feature_dims2 = data2[0][1]\n",
    "feature_dims3 = data3[0][1]\n",
    "feature_dims4 = data4[0][1]\n",
    "\n",
    "clips = [np.copy(d[0]) for d in data]\n",
    "clips2 = [np.copy(d[0]) for d in data2]\n",
    "clips3 = [np.copy(d[0]) for d in data3]\n",
    "clips4 = [np.copy(d[0]) for d in data4]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8   24   48\n",
      "372 372 348 288\n"
     ]
    }
   ],
   "source": [
    "phase_dim = sum([feature_dims[feature] for feature in phase_features])\n",
    "pose_dim = sum([feature_dims[feature] for feature in pose_features])\n",
    "pose_dim2 = sum([feature_dims2[feature] for feature in pose_features])\n",
    "pose_dim3 = sum([feature_dims3[feature] for feature in pose_features])\n",
    "pose_dim4 = sum([feature_dims4[feature] for feature in pose_features])\n",
    "cost_dim = sum([feature_dims[feature] for feature in cost_features])\n",
    "target_dim = sum([feature_dims[feature] for feature in target_features])\n",
    "print(phase_dim, \" \", cost_dim, \" \", target_dim)\n",
    "print(pose_dim, pose_dim2, pose_dim3, pose_dim4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "x_tensors = torch.stack([F.normaliseT(torch.from_numpy(clip[:-1])).float() for clip in clips])\n",
    "y_tensors = torch.stack([torch.from_numpy(clip[1:]).float() for clip in clips])\n",
    "\n",
    "x_tensors2 = torch.stack([F.normaliseT(torch.from_numpy(clip[:-1])).float() for clip in clips2])\n",
    "y_tensors2 = torch.stack([torch.from_numpy(clip[1:]).float() for clip in clips2])\n",
    "\n",
    "x_tensors3 = torch.stack([F.normaliseT(torch.from_numpy(clip[:-1])).float() for clip in clips3])\n",
    "y_tensors3 = torch.stack([torch.from_numpy(clip[1:]).float() for clip in clips3])\n",
    "\n",
    "x_tensors4 = torch.stack([F.normaliseT(torch.from_numpy(clip[:-1])).float() for clip in clips4])\n",
    "y_tensors4 = torch.stack([torch.from_numpy(clip[1:]).float() for clip in clips4])\n",
    "\n",
    "pose_data1 = x_tensors[:,  :,  phase_dim:phase_dim+pose_dim]\n",
    "pose_data2 = x_tensors2[:, :, phase_dim:phase_dim+pose_dim2]\n",
    "pose_data3 = x_tensors3[:, :, phase_dim:phase_dim+pose_dim3]\n",
    "pose_data4 = x_tensors4[:, :, phase_dim:phase_dim+pose_dim4]\n",
    "pose_data = torch.cat((pose_data1, pose_data2, pose_data3, pose_data4), dim=2)\n",
    "\n",
    "dataset = TensorDataset(pose_data, pose_data)\n",
    "datasetR1 = TensorDataset(x_tensors, y_tensors)\n",
    "datasetR2 = TensorDataset(x_tensors2, y_tensors2)\n",
    "datasetR3 = TensorDataset(x_tensors3, y_tensors3)\n",
    "datasetR4 = TensorDataset(x_tensors4, y_tensors4)\n",
    "datasetR1_R3 = TensorDataset(x_tensors, y_tensors3)\n",
    "\n",
    "N = len(x_tensors)\n",
    "\n",
    "train_ratio = int(.7*N)\n",
    "val_ratio = int((N-train_ratio) / 2.0)\n",
    "test_ratio = N - train_ratio - val_ratio\n",
    "train_set, val_set, test_set = random_split(dataset, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR1, val_setR1, test_setR1 = random_split(datasetR1, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR2, val_setR2, test_setR2 = random_split(datasetR2, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR3, val_setR3, test_setR3 = random_split(datasetR3, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR4, val_setR4, test_setR4 = random_split(datasetR4, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR1_3, val_setR1_3, test_setR1_3 = random_split(datasetR1_R3, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "# print(len(train_set), len(val_set), len(test_set))\n",
    "# print(len(train_set2), len(val_set2), len(test_set2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def extract_targets(train_set, val_set, test_set, target_dim):\n",
    "    t1, t2, t3, t33 = [], [], [], []\n",
    "    for i in range(len(train_set)):\n",
    "        x = train_set[i][0]\n",
    "        y = train_set[i][1]\n",
    "        t1.append((x[:, :-target_dim], y[:, :-target_dim]))\n",
    "    for i in range(len(val_set)):\n",
    "        x = val_set[i][0]\n",
    "        y = val_set[i][1]\n",
    "        t2.append((x[:, :-target_dim:], y[:, :-target_dim:]))\n",
    "    for i in range(len(test_set)):\n",
    "        x = test_set[i][0]\n",
    "        y = test_set[i][1]\n",
    "        t3.append((x[:, :-target_dim:], y[:, :-target_dim:]))\n",
    "        t33.append((x[:, :-target_dim:], y))\n",
    "    return t1, t2, t3, t33\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "t1, v1, te1, te11 = extract_targets(train_set=train_setR1, val_set=val_setR1, test_set=test_setR1, target_dim=target_dim)\n",
    "t2, v2, te2, te22 = extract_targets(train_set=train_setR2, val_set=val_setR2, test_set=test_setR2, target_dim=target_dim)\n",
    "t3, v3, te3, te33= extract_targets(train_set=train_setR3, val_set=val_setR3, test_set=test_setR3, target_dim=target_dim)\n",
    "t4, v4, te4, te44 = extract_targets(train_set=train_setR4, val_set=val_setR4, test_set=test_setR4, target_dim=target_dim)\n",
    "t1_3, v1_3, te1_3, te1_33 = extract_targets(train_set=train_setR1_3, val_set=val_setR1_3, test_set=test_setR1_3, target_dim=target_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"/home/nuoc/Documents/MEX/models/version_0.2/MLP_MoE_R1_FULL/0.018650446087121964.pbz2\"\n",
    "\n",
    "with bz2.BZ2File(filename, \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "pose_autoencoder = MLP.load_checkpoint(obj[\"pose_autoencoder_path\"])\n",
    "cost_encoder = MLP.load_checkpoint(obj[\"cost_encoder_path\"])\n",
    "generationModel = MoE.load_checkpoint(obj[\"motionGenerationModelPath\"])\n",
    "\n",
    "model = MotionGenerationModel(config=obj[\"config\"], feature_dims=obj[\"feature_dims\"], Model=MoE,\n",
    "                              input_slicers=obj[\"in_slices\"], output_slicers=obj[\"out_slices\"],\n",
    "                              name=obj[\"name\"])\n",
    "# if MiddleModel is None:\n",
    "MiddleModel = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=pose_autoencoder.dimensions[-1], out_features=pose_autoencoder.dimensions[-1]))\n",
    "\n",
    "MiddleModel.load_state_dict(obj[\"middle_layer_dict\"])\n",
    "model.in_slices = obj[\"in_slices\"]\n",
    "model.out_slices = obj[\"out_slices\"]\n",
    "model.pose_autoencoder = pose_autoencoder\n",
    "model.cost_encoder = cost_encoder\n",
    "model.generationModel = generationModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "MotionGenerationModel(\n  (pose_autoencoder): MLP(\n    (encoder): Sequential(\n      (fc0): Linear(in_features=372, out_features=512, bias=True)\n      (act0): ELU(alpha=1.0)\n      (drop): Dropout(p=0.2, inplace=False)\n      (fc1): Linear(in_features=512, out_features=512, bias=True)\n      (act1): ELU(alpha=1.0)\n      (fc2): Linear(in_features=512, out_features=256, bias=True)\n    )\n    (decoder): Sequential(\n      (fc0): Linear(in_features=256, out_features=512, bias=True)\n      (act0): ELU(alpha=1.0)\n      (drop): Dropout(p=0.2, inplace=False)\n      (fc1): Linear(in_features=512, out_features=512, bias=True)\n      (act1): ELU(alpha=1.0)\n      (fc2): Linear(in_features=512, out_features=372, bias=True)\n    )\n  )\n  (middle_layer): Linear(in_features=256, out_features=256, bias=True)\n  (cost_encoder): MLP(\n    (encoder): Sequential(\n      (fc0): Linear(in_features=24, out_features=128, bias=True)\n      (act0): ELU(alpha=1.0)\n      (drop): Dropout(p=0.2, inplace=False)\n      (fc1): Linear(in_features=128, out_features=128, bias=True)\n      (act1): ELU(alpha=1.0)\n      (fc2): Linear(in_features=128, out_features=128, bias=True)\n    )\n    (decoder): Sequential()\n  )\n  (generationModel): MoE(\n    (gate): Sequential(\n      (0): Linear(in_features=8, out_features=128, bias=True)\n      (1): ELU(alpha=1.0)\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ELU(alpha=1.0)\n      (4): Linear(in_features=128, out_features=4, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_set = train_set\n",
    "model.val_set = val_set\n",
    "model.test_set = test_set\n",
    "model.config = config\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Mixer_name = \"MLPMIX_R1-R4_k=1024\"\n",
    "Mixer_name = \"DEC_R1-R4\"\n",
    "# MLPMIX = MLP_MIX(config=config, input_dims=[pose_dim, pose_dim2, pose_dim3, pose_dim4],\n",
    "#                  train_set=train_set, val_set=val_set, test_set=test_set,\n",
    "#                  name=Mixer_name)\n",
    "\n",
    "dec = DEC(config=config, input_dims=[pose_dim, pose_dim2, pose_dim3, pose_dim4],\n",
    "                 train_set=train_set, val_set=val_set, test_set=test_set,\n",
    "                 name=Mixer_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 200\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"avg_val_loss\", save_top_k=3)\n",
    "earlystopping = EarlyStopping(monitor=\"avg_val_loss\", patience=10)\n",
    "logger=TensorBoardLogger(save_dir=\"logs/\", name=Mixer_name, version=\"0.1\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"/home/nuoc/Documents/MEX/src/motion_generation/checkpoints\",\n",
    "    gpus=1, precision=16,\n",
    "    callbacks=[earlystopping],\n",
    "    min_epochs=20,\n",
    "    logger=logger,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    stochastic_weight_avg=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type      | Params\n",
      "--------------------------------------------\n",
      "0 | cluster_model | DEC_Layer | 262 K \n",
      "--------------------------------------------\n",
      "262 K     Trainable params\n",
      "0         Non-trainable params\n",
      "262 K     Total params\n",
      "1.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0500cd9668541c5b1b65185e27c4504"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84c0a0101c534fb7a30b3e05e75e979d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 10.91 GiB total capacity; 5.37 GiB already allocated; 1.43 GiB free; 7.72 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-94-81672f7634df>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# trainer.fit(MLPMIX)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    498\u001B[0m         \u001B[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 499\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m         \u001B[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mdispatch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    544\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    545\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 546\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    547\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    548\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain_or_test_or_predict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001B[0m in \u001B[0;36mstart_training\u001B[0;34m(self, trainer)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_testing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001B[0m in \u001B[0;36mstart_training\u001B[0;34m(self, trainer)\u001B[0m\n\u001B[1;32m    112\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Trainer'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0;31m# double dispatch to initiate the training loop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_testing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Trainer'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mrun_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    635\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"run_training_epoch\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m                     \u001B[0;31m# run train epoch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 637\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_training_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    638\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    639\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_steps\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_steps\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_step\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mrun_training_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    491\u001B[0m             \u001B[0;31m# ------------------------------------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    492\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"run_training_batch\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 493\u001B[0;31m                 \u001B[0mbatch_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_training_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataloader_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    494\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    495\u001B[0m             \u001B[0;31m# when returning -1 from train_step, we end epoch early\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mrun_training_batch\u001B[0;34m(self, batch, batch_idx, dataloader_idx)\u001B[0m\n\u001B[1;32m    653\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    654\u001B[0m                         \u001B[0;31m# optimizer step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 655\u001B[0;31m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_step_and_backward_closure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    656\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    657\u001B[0m                     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36moptimizer_step\u001B[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m         \u001B[0;31m# model hook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 426\u001B[0;31m         model_ref.optimizer_step(\n\u001B[0m\u001B[1;32m    427\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcurrent_epoch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m             \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\u001B[0m in \u001B[0;36moptimizer_step\u001B[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m             \u001B[0;31m# wraps into LightingOptimizer only for running step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1386\u001B[0m             \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLightningOptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_to_lightning_optimizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1387\u001B[0;31m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptimizer_closure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1388\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1389\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0moptimizer_zero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_idx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure, *args, **kwargs)\u001B[0m\n\u001B[1;32m    212\u001B[0m             \u001B[0mprofiler_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 214\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__optimizer_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprofiler_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprofiler_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    215\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_total_optimizer_step_calls\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001B[0m in \u001B[0;36m__optimizer_step\u001B[0;34m(self, closure, profiler_name, **kwargs)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofiler_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 134\u001B[0;31m             \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlambda_closure\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    135\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mCallable\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001B[0m in \u001B[0;36moptimizer_step\u001B[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001B[0m\n\u001B[1;32m    271\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m         \"\"\"\n\u001B[0;32m--> 273\u001B[0;31m         make_optimizer_step = self.precision_plugin.pre_optimizer_step(\n\u001B[0m\u001B[1;32m    274\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlightning_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlambda_closure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    275\u001B[0m         )\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/native_amp.py\u001B[0m in \u001B[0;36mpre_optimizer_step\u001B[0;34m(self, pl_module, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001B[0m\n\u001B[1;32m     76\u001B[0m                 \u001B[0;34m\" To request, please file a Github issue in PyTorch and tag @mcarilli\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m             )\n\u001B[0;32m---> 78\u001B[0;31m         \u001B[0mlambda_closure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mpl_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautomatic_optimization\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mtrain_step_and_backward_closure\u001B[0;34m()\u001B[0m\n\u001B[1;32m    647\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    648\u001B[0m                         \u001B[0;32mdef\u001B[0m \u001B[0mtrain_step_and_backward_closure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 649\u001B[0;31m                             result = self.training_step_and_backward(\n\u001B[0m\u001B[1;32m    650\u001B[0m                                 \u001B[0msplit_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhiddens\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    651\u001B[0m                             )\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mtraining_step_and_backward\u001B[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001B[0m\n\u001B[1;32m    741\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"training_step_and_backward\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m             \u001B[0;31m# lightning module hook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 743\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msplit_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhiddens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    744\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_curr_step_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    745\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001B[0m\n\u001B[1;32m    291\u001B[0m             \u001B[0mmodel_ref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"training_step\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 293\u001B[0;31m                 \u001B[0mtraining_step_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    294\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpost_training_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprecision_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 156\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    157\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpost_training_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlightning_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpost_training_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/MEX/src/version_0.2/rig_agnostic_encoding/models/DEC.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m         \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprediction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/MEX/src/version_0.2/rig_agnostic_encoding/models/DEC.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[0mencoded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_tensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactive_models\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m         \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcluster_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvec\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvec\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mencoded\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    106\u001B[0m         \u001B[0mdecoded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactive_models\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/MEX/src/version_0.2/rig_agnostic_encoding/models/DEC.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[0mencoded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_tensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactive_models\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m         \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcluster_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvec\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvec\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mencoded\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    106\u001B[0m         \u001B[0mdecoded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactive_models\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/MEX/src/version_0.2/rig_agnostic_encoding/models/DEC.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mFloatTensor\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mbatch\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber\u001B[0m \u001B[0mof\u001B[0m \u001B[0mclusters\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \"\"\"\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mnorm_squared\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcluster_centers\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m         \u001B[0mnumerator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1.0\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m1.0\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mnorm_squared\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malpha\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0mpower\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malpha\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 10.91 GiB total capacity; 5.37 GiB already allocated; 1.43 GiB free; 7.72 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# trainer.fit(MLPMIX)\n",
    "trainer.fit(dec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44832ca0d07f4cc6a4855599ec39764d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'ptl/test_loss': 0.4838775396347046, 'test_loss': 0.49839645624160767}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.49839645624160767, 'ptl/test_loss': 0.4838775396347046}]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(MLPMIX)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# model_name = \"MLP_MoE_R1_Two_v2\"\n",
    "# model_name = \"MLP_MoE_R2_Two\"\n",
    "model_name = \"MLP_MoE_R3_Two_v2\"\n",
    "# model_name = \"MLP_MoE_R4_Two\"\n",
    "\n",
    "featureDim = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    # \"pose_dim\": pose_dim,\n",
    "    # \"pose_dim\": pose_dim2,\n",
    "    \"pose_dim\": pose_dim3,\n",
    "    # \"pose_dim\": pose_dim4,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim\n",
    "    }\n",
    "\n",
    "# in_slice = [phase_dim, pose_dim, cost_dim]\n",
    "# in_slice = [phase_dim, pose_dim2, cost_dim]\n",
    "in_slice = [phase_dim, pose_dim3, cost_dim]\n",
    "# in_slice = [phase_dim, pose_dim4, cost_dim]\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "temp = MLP_MIX(config=config, input_dims=[pose_dim,pose_dim2, pose_dim3, pose_dim4])\n",
    "# pose_encoder = temp.active_models[0]\n",
    "# pose_encoder = temp.active_models[1]\n",
    "pose_encoder = temp.active_models[2]\n",
    "# pose_encoder = temp.active_models[3]\n",
    "# pose_encoder.encoder.load_state_dict(MLPMIX.active_models[0].encoder.state_dict())\n",
    "# pose_encoder.decoder.load_state_dict(MLPMIX.active_models[0].decoder.state_dict())\n",
    "\n",
    "# pose_encoder.encoder.load_state_dict(MLPMIX.active_models[1].encoder.state_dict())\n",
    "# pose_encoder.decoder.load_state_dict(MLPMIX.active_models[1].decoder.state_dict())\n",
    "\n",
    "pose_encoder.encoder.load_state_dict(MLPMIX.active_models[2].encoder.state_dict())\n",
    "pose_encoder.decoder.load_state_dict(MLPMIX.active_models[2].decoder.state_dict())\n",
    "\n",
    "# pose_encoder.encoder.load_state_dict(MLPMIX.active_models[3].encoder.state_dict())\n",
    "# pose_encoder.decoder.load_state_dict(MLPMIX.active_models[3].decoder.state_dict())\n",
    "# middle_layer = torch.nn.Sequential()\n",
    "# middle_layer = temp.cluster_model\n",
    "# middle_layer.load_state_dict(MLPMIX.cluster_model.state_dict())\n",
    "# cost_encoder = model2.cost_encoder\n",
    "\n",
    "# generation_model = model2.generationModel\n",
    "model = MotionGenerationModel_v2(config=config, Model=MoE, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim,\n",
    "                                 input_slicers=in_slice, output_slicers=out_slice,\n",
    "                                 # train_set=t1, val_set=v1, test_set=te1,\n",
    "                                 # train_set=t2, val_set=v2, test_set=te2,\n",
    "                                 train_set=t3, val_set=v3, test_set=te3,\n",
    "                                 # train_set=t4, val_set=v4, test_set=te4,\n",
    "                                 name=model_name\n",
    "                                   )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "model2 = MotionGenerationModel_v2.load_checkpoint(\n",
    "    \"/home/nuoc/Documents/MEX/models/version_0.2/MLP_MoE_R1_Two/0.0415918305516243.pbz2\",\n",
    "    Model=MoE, MiddleModel=middle_layer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generationModel.gate.load_state_dict(model2.generationModel.gate.state_dict())\n",
    "model.generationModel.load_state_dict(model2.generationModel.state_dict())\n",
    "\n",
    "# model.generationModel.freeze()\n",
    "# model.cost_encoder.freeze()\n",
    "# model.middle_layer.requires_grad_(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_EPOCHS = 50\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"avg_val_loss\", save_top_k=3)\n",
    "earlystopping = EarlyStopping(monitor=\"avg_val_loss\", patience=20)\n",
    "logger=TensorBoardLogger(save_dir=\"logs/\", name=model_name, version=\"0.3\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"/home/nuoc/Documents/MEX/src/motion_generation/checkpoints\",\n",
    "    gpus=1, precision=16,\n",
    "    # callbacks=[earlystopping],\n",
    "    min_epochs=20,\n",
    "    logger=logger,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    stochastic_weight_avg=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | pose_autoencoder | MLP        | 1.4 M \n",
      "1 | middle_layer     | Sequential | 0     \n",
      "2 | cost_encoder     | MLP        | 36.2 K\n",
      "3 | generationModel  | MoE        | 3.5 M \n",
      "------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 M     Total params\n",
      "19.768    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4025a8c15dfe4cdbb08cbf99e00583ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4273b1b7dd654b4482edb842df1f0631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d09140f8754b4ab395a90d84e78f3533"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e115350b9724910b27b63aaf14dca29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33cdb08e575e450c9d4b1f81bf5794e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0121b85c7ce9483ca0607a3d77a32a61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1f8532854b343209913f290798d16a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2599052276fa4e5b8356ce688adc23f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2c381238a6e4029bdce0878a77d2501"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e990859b01a241b1b43fdf9822d207fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b320e187e8734009803bc0aa831484da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8632f7c6189c428d89a04bcfb7b1128f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0483f7c896eb44eeb3617d0010f6a566"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65dc4c794aa3486a85a6c2b7242de2ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48850d826baa4783ae339235c903dc4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91cf708a7b5c452fa82c61c50d1b4fbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df8ea7fd0069402abb8f589b95c1a0c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "747968412bdd499da776c6a3930762ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "886977e4742740348c42d10b40fa2b51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "567cb4ce9d9345bdbc98793afce7c64a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7ac840799bb40abbde1b809b088735c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4f05127fe754d70a05d2a13bbb986e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5edea9a039d74a4989d2e14162c8b9e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbb997e073c14f2196750d7bd93a4051"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b785c9edc7c64499b9be4366d94cf3f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd6df8b812724daebc09aed55b50195d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b99160d842fa4973903ddaefa404c004"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19193a9adc34458b8e191fbf5492dd85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "532d97a032a84801970338dfca296740"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b34f17fe2e064204b831b0280d9fa2dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0389e3253a4f47a69170b8873e79a663"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d93db9c056ea45e8a7075f4b56e7d895"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42234af82b5b4b7791f51ac14eb277d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f5296230b84498f9f37f63480300258"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b25bd075a6fd4d418fc424220ef5115f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9af69ed946e846d5ad5d664a99102a1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cbc76cd8dbb4dd1911fe448ca736a3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "301deff375fe436197699d3a0713a596"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28e64d5e775040ce93706a6b12d9c804"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa9b1c0d1fa045ce97a210734f05cb4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "230a5d151c86443dbcf84678a95cfe65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuoc/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: Swapping lr_scheduler <torch.optim.lr_scheduler.StepLR object at 0x7f8e20da4ca0> for <torch.optim.swa_utils.SWALR object at 0x7f8e20777460>\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5da0c1ca885b451692aeda7628672887"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a45ae0facd59446d9c6f3145fac37270"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c987d5daced40cfb7a7aa3bb9b79c58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c44be8e0922468a9be522a099d5bde1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "252d2a31940a4c4094b67ba710fac236"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e90ad481ad5042eca66206155e40e595"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e31c88704f074e03a4285fd33a92834f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27ce2a5678684d9c801cc0b4384d90c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4535d5ef00a74702807a2c1c8f616e9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2998e2180134bf296bf716c3a12209a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cae249275a9418db67cb5ce7706d99d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb8255139db74708a71d11678abc5ce4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'ptl/test_loss': 0.06277039647102356, 'test_loss': 0.09937182813882828}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.09937182813882828, 'ptl/test_loss': 0.06277039647102356}]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model2 = model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86bd0dcb2434406888e016110fae90d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'ptl/test_loss': 0.055365629494190216, 'test_loss': 0.09592478722333908}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.09592478722333908, 'ptl/test_loss': 0.055365629494190216}]"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = []\n",
    "for i in range(len(test_setR4)):\n",
    "    x = test_setR4[i][0]\n",
    "    y = test_setR4[i][1]\n",
    "    te.append((x[:, :-target_dim:], y[:, :-target_dim]))\n",
    "\n",
    "trainer.test(model, test_dataloaders=DataLoader(te, pin_memory=True, num_workers=6))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "# te = te11\n",
    "# te = te2\n",
    "te = te33\n",
    "# te = te4\n",
    "n = 10\n",
    "idx = np.random.randint(0, len(te), n)\n",
    "original = []\n",
    "generated = []\n",
    "# pose_idx_upper = feature_dims2[\"phase_dim\"] + feature_dims[\"pos\"] + feature_dims[\"rotMat2\"]\n",
    "pose_idx_upper = model.in_slices[1] + feature_dims[\"pos\"] + feature_dims[\"rotMat2\"]\n",
    "print(pose_idx_upper)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%d\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "model.autoregress_prob = 1\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    # for i in range(1):\n",
    "    # original =\n",
    "    # x = x_tensors[idx]\n",
    "    x = torch.stack([te[i][0] for i in idx])\n",
    "    y = torch.stack([te[i][1] for i in idx])\n",
    "    shape = x.shape\n",
    "    x = x.view(-1, shape[-1])\n",
    "\n",
    "    # x = x.view(-1, 13, shape[-1])\n",
    "    # x_c = x[:,0,:]\n",
    "    # n = shape[1]\n",
    "    g_frames = []\n",
    "    #\n",
    "    # for i in range(0, 13):\n",
    "    out= model(x)\n",
    "    x_c = torch.cat(out,dim=1).detach()\n",
    "    # g_frames.append(x_c.unsqueeze(1))\n",
    "\n",
    "    # out = torch.cat(model(x), dim=1).view(shape)\n",
    "            # x_c = torch.cat(out, dim=1)\n",
    "    # g_frames.append(x_c.unsqueeze(1))\n",
    "        # original.append(o_frames)\n",
    "    # generated.append(torch.cat(g_frames, dim=1))\n",
    "    generated = x_c\n",
    "    # generated = torch.cat(g_frames, dim=1)\n",
    "    generated = generated.view(shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 299, 428])\n",
      "torch.Size([10, 299, 380])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())\n",
    "print(generated.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 299, 93]) torch.Size([10, 299, 186]) torch.Size([10, 299, 93])\n",
      "torch.Size([10, 299, 93]) torch.Size([10, 299, 186]) torch.Size([10, 299, 93])\n",
      "torch.Size([10, 299, 12]) torch.Size([10, 299, 36])\n"
     ]
    }
   ],
   "source": [
    "phase_dim = feature_dims[\"phase_vec_l2\"]\n",
    "toPosDim = phase_dim+feature_dims[\"pos\"]\n",
    "toRotDim = toPosDim + feature_dims[\"rotMat2\"]\n",
    "toVelDim = toRotDim + feature_dims[\"velocity\"]\n",
    "\n",
    "gPos = generated[:, :, phase_dim:toPosDim]\n",
    "gRot = generated[:, :, toPosDim:toRotDim]\n",
    "gVel = generated[:, :, toRotDim:toVelDim]\n",
    "\n",
    "oPos = y[:, :, phase_dim:toPosDim]\n",
    "oRot = y[:, :, toPosDim:toRotDim]\n",
    "oVel = y[:, :, toRotDim:toVelDim]\n",
    "\n",
    "tPos = y[:, :, -target_dim:-target_dim+3*4]\n",
    "tRot = y[:, :, -target_dim+3*4:]\n",
    "\n",
    "print(gPos.shape, gRot.shape, gVel.shape)\n",
    "print(oPos.shape, oRot.shape, oVel.shape)\n",
    "print(tPos.shape, tRot.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos loss:  tensor(0.0188)\n",
      "Rot loss:  tensor(0.0492)\n",
      "Vel loss:  tensor(0.0494)\n"
     ]
    }
   ],
   "source": [
    "clip_length = gPos.shape[1]\n",
    "gPos_r = gPos.reshape((n, clip_length, -1, 3))\n",
    "gRot_r = gRot.reshape((n, clip_length, -1, 3, 2))\n",
    "gVel_r = gVel.reshape((n, clip_length, -1, 3))\n",
    "\n",
    "oPos_r = oPos.reshape((n, clip_length, -1, 3))\n",
    "oRot_r = oRot.reshape((n, clip_length, -1, 3, 2))\n",
    "oVel_r = oVel.reshape((n, clip_length, -1, 3))\n",
    "\n",
    "tPos_r = tPos.reshape((n, clip_length, -1, 3))\n",
    "tRot_r = tRot.reshape((n, clip_length, -1, 3, 3))\n",
    "\n",
    "print(\"Pos loss: \", torch.nn.functional.mse_loss(gPos_r, oPos_r))\n",
    "print(\"Rot loss: \", torch.nn.functional.mse_loss(gRot_r, oRot_r))\n",
    "print(\"Vel loss: \", torch.nn.functional.mse_loss(gVel_r, oVel_r))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "template = js.load(open(\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/TestAll_1_R1_One_1/False_2_0.json\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def setVec3(struct, vec):\n",
    "    struct[\"x\"] = vec[0].item()\n",
    "    struct[\"y\"] = vec[1].item()\n",
    "    struct[\"z\"] = vec[2].item()\n",
    "\n",
    "def setVec6(struct, vec):\n",
    "    for r, cell in enumerate([\"x\", \"y\", \"z\"]):\n",
    "        for col, column in enumerate([\"c0\", \"c1\"]):\n",
    "            struct[column][cell] = vec[r, col].item()\n",
    "\n",
    "def insert_pos(positions, rotations, velocity, tPos, tRot, name=\"Replay\"):\n",
    "    shape = positions.shape\n",
    "    for c in range(shape[0]):\n",
    "        for f in range(shape[1]):\n",
    "            t = 0\n",
    "            for j in range(shape[2]):\n",
    "                jo = template[\"frames\"][f][\"joints\"][j]\n",
    "                setVec3(jo[\"position\"], positions[c,f,j])\n",
    "                setVec3(jo[\"velocity\"], velocity[c,f,j])\n",
    "                setVec6(jo[\"rotMat\"], rotations[c,f,j])\n",
    "\n",
    "                # jo[\"position\"][\"x\"] = positions[c,f,j,0].item()\n",
    "                # jo[\"position\"][\"y\"] = positions[c,f,j,1].item()\n",
    "                # jo[\"position\"][\"z\"] = positions[c,f,j,2].item()\n",
    "\n",
    "                # jo[\"velocity\"][\"x\"] = velocity[c,f,j,0].item()\n",
    "                # jo[\"velocity\"][\"y\"] = velocity[c,f,j,1].item()\n",
    "                # jo[\"velocity\"][\"z\"<] = velocity[c,f,j,2].item()\n",
    "                #\n",
    "                # for r, cell in enumerate([\"x\", \"y\", \"z\"]):\n",
    "                #     for col, column in enumerate([\"c0\", \"c1\"]):\n",
    "                #         jo[\"rotMat\"][column][cell] = rotations[c,f,j,r, col].item()\n",
    "\n",
    "                if jo[\"key\"]:\n",
    "                    setVec3(jo[\"cost\"][\"TargetPosition\"], tPos[c,f,t])\n",
    "                    setVec6(jo[\"cost\"][\"TargetRotation\"], tRot[c,f,t])\n",
    "                    t+=1\n",
    "                    # jo[\"targetPosition\"][\"x\"] = tPos[c, f, t, 0]\n",
    "                    # jo[\"targetPosition\"][\"y\"] = tPos[c, f, t, 1]\n",
    "                    # jo[\"targetPosition\"][\"z\"] = tPos[c, f, t, 2]\n",
    "\n",
    "                    # for r, cell in enumerate([\"x\", \"y\", \"z\"]):\n",
    "                    #     for col, column in enumerate([\"c0\", \"c1\"]):\n",
    "                    #         jo[\"rotMat\"][column][cell] = rotations[c,f,j,r, col].item()\n",
    "        with open(\"{}_{}.json\".format(name, c), \"w\") as f:\n",
    "            js.dump(template, f)\n",
    "\n",
    "# os.mkdir(\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/R1_ALL\")\n",
    "insert_pos(oPos_r, oRot_r, oVel_r, tPos_r, tRot_r,\n",
    "           \"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/R1_ALL/\"+model_name+\"_v4_Original\")\n",
    "insert_pos(gPos_r, gRot_r, oVel_r, tPos_r, tRot_r,\n",
    "           \"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/R1_ALL/\"+model_name+\"_v4_Generated\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}