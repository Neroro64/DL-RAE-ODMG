{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"motion_generation\")\n",
    "sys.path.append(\"rig_agnostic_encoding/functions\")\n",
    "sys.path.append(\"rig_agnostic_encoding/models\")\n",
    "\n",
    "from motion_generation.MoE import MoE\n",
    "from motion_generation.MoE_Z import MoE as MoE_Z\n",
    "import motion_generation\n",
    "from motion_generation.GRU import GRU\n",
    "from motion_generation.GRU_Z import GRU as GRU_Z\n",
    "from motion_generation.LSTM import LSTM\n",
    "from motion_generation.LSTM_Z import LSTM as LSTM_Z\n",
    "\n",
    "from motion_generation.MotionGeneration import MotionGenerationModel as MoGen\n",
    "from motion_generation.MotionGenerationEmbedd import MotionGenerationModel as MoGenZ\n",
    "from motion_generation.MotionGenerationVAE import MotionGenerationModel as MoGenVAE\n",
    "from motion_generation.MotionGenerationVAE_Embedd import MotionGenerationModel as MoGenVAE_Z\n",
    "\n",
    "from MLP import MLP\n",
    "from MLP_Adversarial import MLP_ADV\n",
    "from MLP_MIX import MLP_MIX\n",
    "from RBF import RBF\n",
    "from VAE import VAE\n",
    "\n",
    "from rig_agnostic_encoding.functions.DataProcessingFunctions import clean_checkpoints\n",
    "from GlobalSettings import MODEL_PATH\n",
    "import bz2\n",
    "from cytoolz import concat, sliding_window, accumulate\n",
    "from operator import add\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import func as F\n",
    "import _pickle as pickle\n",
    "import json as js\n",
    "import importlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"hidden_dim\": 256,\n",
    "    \"k\": 256,\n",
    "    \"z_dim\": 256,\n",
    "    \"lr\": 1e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"keep_prob\": 0,\n",
    "    \"loss_fn\":torch.nn.functional.mse_loss,\n",
    "    \"optimizer\":torch.optim.AdamW,\n",
    "    \"scheduler\":torch.optim.lr_scheduler.StepLR,\n",
    "    \"scheduler_param\": {\"step_size\":80, \"gamma\":.9},\n",
    "    \"basis_func\":\"gaussian\",\n",
    "    \"n_centroid\":64,\n",
    "    \"k_experts\": 4,\n",
    "    \"gate_size\": 128,\n",
    "    \"g_hidden_dim\": 512,\n",
    "    \"num_layers\": 4,\n",
    "    \"autoregress_prob\":0,\n",
    "    \"autoregress_inc\":.3,\n",
    "    \"autoregress_ep\":20,\n",
    "    \"autoregress_max_prob\":1,\n",
    "    \"cost_hidden_dim\":128,\n",
    "    \"seq_len\":13,\n",
    "    \"device\":\"cuda\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getFilesNames(file_paths, data_path, MAX_FILES=-1):\n",
    "    for dname, dirs, files in os.walk(data_path):\n",
    "        for i, file in enumerate(files):\n",
    "            file_paths.append(os.path.join(dname, file))\n",
    "            if MAX_FILES > 0 and i >= MAX_FILES:\n",
    "                break\n",
    "    return file_paths\n",
    "\n",
    "data_path = \"/home/nuoc/Documents/MEX/data/data/Dataset_R1_Two_1\"\n",
    "data_path2 = \"/home/nuoc/Documents/MEX/data/data/Dataset_R2_Two_1\"\n",
    "# data_path3 = \"/home/nuoc/Documents/MEX/data/data/Dataset_R3_Two_1\"\n",
    "# data_path4 = \"/home/nuoc/Documents/MEX/data/data/Dataset_R4_Two_1\"\n",
    "file_paths = getFilesNames([],data_path)\n",
    "file_paths2 = getFilesNames([],data_path2)\n",
    "# file_paths3 = getFilesNames([],data_path3)\n",
    "# file_paths4 = getFilesNames([],data_path4)\n",
    "\n",
    "print(len(file_paths))\n",
    "print(len(file_paths2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phase_features = [\"phase_vec_l2\"]\n",
    "pose_features = [\"pos\", \"rotMat2\", \"velocity\"]\n",
    "cost_features = [\"posCost\", \"rotCost\"]\n",
    "pose_label_feature = [\"chainPos\", \"isLeft\", \"geoDistanceNormalised\"]\n",
    "target_features = [\"targetPosition\", \"targetRotation\"]\n",
    "features = phase_features + pose_features + cost_features + target_features\n",
    "clips = []\n",
    "feature_dims = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = F.process_data_multithread(file_paths, features)\n",
    "data2 = F.process_data_multithread(file_paths2, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pose_labels1 = F.process_data_multithread([file_paths[0]], pose_label_feature)\n",
    "pose_labels2 = F.process_data_multithread([file_paths2[0]], pose_label_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obj = {\"data\":data, \"data2\":data2, \"pose_label1\":pose_labels1, \"pose_label2\":pose_labels2}\n",
    "F.save(obj, filename=\"transfer_learning_set_R1-R2_Two_wTarget\", path=\"/home/nuoc/Documents/MEX/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obj = F.load(\"/home/nuoc/Documents/MEX/data/transfer_learning_set_R1-R2_Two_wTarget.pbz2\")\n",
    "data = obj[\"data\"]\n",
    "data2 = obj[\"data2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pose_labels1 = obj[\"pose_label1\"]\n",
    "pose_labels2 = obj[\"pose_label2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_dims = data[0][1]\n",
    "feature_dims2 = data2[0][1]\n",
    "clips = [np.copy(d[0]) for d in data]\n",
    "clips2 = [np.copy(d[0]) for d in data2]\n",
    "\n",
    "pose_labels1 = pose_labels1[0]\n",
    "pose_labels2 = pose_labels2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phase_dim = sum([feature_dims[feature] for feature in phase_features])\n",
    "pose_dim = sum([feature_dims[feature] for feature in pose_features])\n",
    "pose_dim2 = sum([feature_dims2[feature] for feature in pose_features])\n",
    "cost_dim = sum([feature_dims[feature] for feature in cost_features])\n",
    "target_dim = sum([feature_dims[feature] for feature in target_features])\n",
    "print(phase_dim, \" \", cost_dim, \" \", target_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_tensors = torch.stack([F.normaliseT(torch.from_numpy(clip[:-1])).float() for clip in clips])\n",
    "y_tensors = torch.stack([torch.from_numpy(clip[1:]).float() for clip in clips])\n",
    "\n",
    "x_tensors2 = torch.stack([F.normaliseT(torch.from_numpy(clip[:-1])).float() for clip in clips2])\n",
    "y_tensors2 = torch.stack([torch.from_numpy(clip[1:]).float() for clip in clips2])\n",
    "\n",
    "\n",
    "pose_data1 = x_tensors[:,  :,  phase_dim:phase_dim+pose_dim]\n",
    "pose_data2 = x_tensors2[:, :, phase_dim:phase_dim+pose_dim2]\n",
    "pose_data = torch.cat((pose_data1, pose_data2), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_p = TensorDataset(pose_data, pose_data)\n",
    "dataset_p1 = TensorDataset(pose_data1, pose_data1)\n",
    "dataset_p2 = TensorDataset(pose_data2, pose_data2)\n",
    "datasetR1 = TensorDataset(x_tensors, y_tensors)\n",
    "datasetR2 = TensorDataset(x_tensors2, y_tensors2)\n",
    "\n",
    "N = len(x_tensors)\n",
    "\n",
    "train_ratio = int(.7*N)\n",
    "val_ratio = int((N-train_ratio) / 2.0)\n",
    "test_ratio = N - train_ratio - val_ratio\n",
    "\n",
    "train_set_p, val_set_p, test_set_p = random_split(dataset_p, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_set_p1, val_set_p1, test_set_p1 = random_split(dataset_p1, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_set_p2, val_set_p2, test_set_p2 = random_split(dataset_p2, [val_ratio*2, val_ratio, train_ratio-test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_set_p2_F, val_set_p2_F, test_set_p2_F = random_split(dataset_p2, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR1, val_setR1, test_setR1 = random_split(datasetR1, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR2, val_setR2, test_setR2 = random_split(datasetR2, [val_ratio, val_ratio, train_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "train_setR2_F, val_setR2_F, test_setR2_F = random_split(datasetR2, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_targets(train_set, val_set, test_set, target_dim):\n",
    "    t1, t2, t3, t33 = [], [], [], []\n",
    "    for i in range(len(train_set)):\n",
    "        x = train_set[i][0]\n",
    "        y = train_set[i][1]\n",
    "        t1.append((x[:, :-target_dim], y[:, :-target_dim]))\n",
    "    for i in range(len(val_set)):\n",
    "        x = val_set[i][0]\n",
    "        y = val_set[i][1]\n",
    "        t2.append((x[:, :-target_dim:], y[:, :-target_dim:]))\n",
    "    for i in range(len(test_set)):\n",
    "        x = test_set[i][0]\n",
    "        y = test_set[i][1]\n",
    "        t3.append((x[:, :-target_dim:], y[:, :-target_dim:]))\n",
    "        t33.append((x[:, :-target_dim:], y))\n",
    "    return t1, t2, t3, t33\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t1, v1, te1, te11 = extract_targets(train_set=train_setR1, val_set=val_setR1, test_set=test_setR1, target_dim=target_dim)\n",
    "t2, v2, te2, te22 = extract_targets(train_set=train_setR2, val_set=val_setR2, test_set=test_setR2, target_dim=target_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# AE ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "h_dim = train_set_p1[0][0].shape[0]\n",
    "w_dim = train_set_p1[0][0].shape[1]\n",
    "\n",
    "ae_name1 = \"AE_R1\"\n",
    "# ae1 = MLP_ADV(config=config, dimensions=[pose_dim], h_dim=h_dim, w_dim=w_dim,\n",
    "#                  pos_dim=feature_dims[\"pos\"], rot_dim=feature_dims[\"rotMat2\"], vel_dim=feature_dims[\"velocity\"],\n",
    "#                  train_set=train_set_p1, val_set=val_set_p1, test_set=test_set_p1, name=ae_name1)\n",
    "#\n",
    "# ae1 = MLP_ADV.load_checkpoint(\"/home/nuoc/Documents/MEX/models/version_0.3/AE_R1/0.001.256.pbz2\")\n",
    "# ae1.name = ae_name1\n",
    "def load_ae(path):\n",
    "    with bz2.BZ2File(path, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    model = MLP_ADV(config=obj[\"config\"], single_module=obj[\"single_module\"], pose_labels=obj[\"pose_labels\"],\n",
    "                h_dim=h_dim, w_dim=w_dim,\n",
    "                name=obj[\"name\"], dimensions=obj[\"dimensions\"])\n",
    "\n",
    "    model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "    model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "    model.convDiscriminator.load_state_dict(obj[\"discriminator\"])\n",
    "    model.pos_dim = obj[\"dims\"][0]\n",
    "    model.rot_dim = obj[\"dims\"][1]\n",
    "    model.vel_dim = obj[\"dims\"][2]\n",
    "    return model\n",
    "\n",
    "ae1 = load_ae(\"/home/nuoc/Documents/MEX/models/version_0.3/AE_R1/0.001.256.pbz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ae_name2 = \"AE_R2\"\n",
    "# ae2 = MLP_ADV(config=config, dimensions=[pose_dim2],h_dim=h_dim, w_dim=w_dim,\n",
    "#                  pos_dim=feature_dims2[\"pos\"], rot_dim=feature_dims2[\"rotMat2\"], vel_dim=feature_dims2[\"velocity\"],\n",
    "#                  train_set=train_set_p2_F, val_set=val_set_p2_F, test_set=test_set_p2_F, name=ae_name2)\n",
    "#\n",
    "# ae2 = MLP_ADV.load_checkpoint(\"/home/nuoc/Documents/MEX/models/version_0.3/AE_R2/0.002.256.pbz2\")\n",
    "ae2 = load_ae(\"/home/nuoc/Documents/MEX/models/version_0.3/AE_R2/0.002.256.pbz2\")\n",
    "# ae2.name = ae_name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ae1.test_set = test_set_p1\n",
    "ae2.test_set = test_set_p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer()\n",
    "trainer.test(ae1)\n",
    "trainer.test(ae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit(model, name, version=\"0.1\", MIN_EPOCHS=20, MAX_EPOCHS=100, useEarlyStopping=False, patience=10):\n",
    "    if useEarlyStopping:\n",
    "        earlystopping = EarlyStopping(monitor=\"avg_val_loss\",patience=patience)\n",
    "        callbacks = [earlystopping]\n",
    "    else:\n",
    "        callbacks = []\n",
    "    logger=TensorBoardLogger(save_dir=\"logs/\", name=name, version=version)\n",
    "\n",
    "    trainer = pl.Trainer(logger=logger, gpus=1, precision=16)\n",
    "    trainer.test(model)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=\"/home/nuoc/Documents/MEX/src/motion_generation/checkpoints\",\n",
    "        gpus=1, precision=16,\n",
    "        callbacks= callbacks,\n",
    "        min_epochs=MIN_EPOCHS,\n",
    "        logger=logger,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        stochastic_weight_avg=True\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(ae1, ae_name1, MAX_EPOCHS=300, useEarlyStopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(ae2, ae_name2, version=\"0.2\", MAX_EPOCHS=300, useEarlyStopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_checkpoints(os.path.join(MODEL_PATH,ae_name1))\n",
    "clean_checkpoints(os.path.join(MODEL_PATH,ae_name2))\n",
    "\n",
    "ae1.save_checkpoint(best_val_loss=0.001)\n",
    "ae2.save_checkpoint(best_val_loss=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_animation_ae(model=ae1, test_set=test_set_p1, feature_dims=feature_dims,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/TestAll_1_R1_One_1/False_2_0.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Replay/\"+ae_name1)\n",
    "generate_animation_ae(model=ae2, test_set=test_set_p2_F, feature_dims=feature_dims2,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Test/R2.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Replay/\"+ae_name2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"MLP_MoE_R1_ADV\"\n",
    "model_name2 = \"MLP_MoE_R2_ADV\"\n",
    "\n",
    "featureDim = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\":target_dim,\n",
    "    \"g_input_dim\": config[\"z_dim\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims[\"pos\"],\n",
    "    \"rot_dim\":feature_dims[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "featureDim2 = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim2,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\": target_dim,\n",
    "    \"g_input_dim\": config[\"z_dim\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims2[\"pos\"],\n",
    "    \"rot_dim\":feature_dims2[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims2[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "\n",
    "in_slice = [phase_dim, pose_dim, cost_dim, target_dim]\n",
    "in_slice2 = [phase_dim, pose_dim2, cost_dim,target_dim]\n",
    "\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim], h_dim=h_dim, w_dim=w_dim,)\n",
    "temp2 = MLP_ADV(config=config, dimensions=[pose_dim2],h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "pose_encoder = temp\n",
    "pose_encoder2 = temp2\n",
    "pose_encoder.encoder.load_state_dict(ae1.encoder.state_dict())\n",
    "pose_encoder.decoder.load_state_dict(ae1.decoder.state_dict())\n",
    "pose_encoder.convDiscriminator.load_state_dict(ae1.convDiscriminator.state_dict())\n",
    "\n",
    "pose_encoder2.encoder.load_state_dict(ae2.encoder.state_dict())\n",
    "pose_encoder2.decoder.load_state_dict(ae2.decoder.state_dict())\n",
    "pose_encoder2.convDiscriminator.load_state_dict(ae2.convDiscriminator.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "middle_layer = torch.nn.Sequential()\n",
    "model1 = MoGen(config=config, Model=MoE, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim, use_advLoss=True,\n",
    "                                 input_slicers=in_slice, output_slicers=out_slice,\n",
    "                                 train_set=train_setR1, val_set=val_setR1, test_set=val_setR1+test_setR1,\n",
    "                                 name=model_name\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2 = MoGen(config=config, Model=MoE, pose_autoencoder=pose_encoder2, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim2, use_advLoss=True,\n",
    "                                 input_slicers=in_slice2, output_slicers=out_slice,\n",
    "                                 train_set=train_setR2, val_set=val_setR2, test_set=val_setR2+test_setR2,\n",
    "                                 name=model_name2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2_F = MoGen(config=config, Model=MoE, pose_autoencoder=pose_encoder2, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim2, use_advLoss=True,\n",
    "                                 input_slicers=in_slice2, output_slicers=out_slice,\n",
    "                                 train_set=train_setR2_F, val_set=val_setR2_F, test_set=val_setR2_F+test_setR2_F,\n",
    "                                 name=model_name2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model1, version=\"0.4\", MAX_EPOCHS=150, name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2.generationModel.gate.load_state_dict(model1.generationModel.gate.state_dict())\n",
    "model2.generationModel.load_state_dict(model1.generationModel.state_dict())\n",
    "\n",
    "fit(model2, name=model_name2, version=\"0.2\", MAX_EPOCHS=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2_F.generationModel.gate.load_state_dict(model1.generationModel.gate.state_dict())\n",
    "model2_F.generationModel.load_state_dict(model1.generationModel.state_dict())\n",
    "\n",
    "fit(model2_F, name=model_name2, version=\"full\", MAX_EPOCHS=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_checkpoints(os.path.join(MODEL_PATH,model_name))\n",
    "clean_checkpoints(os.path.join(MODEL_PATH,model_name2))\n",
    "\n",
    "model1.save_checkpoint(best_val_loss=0.001)\n",
    "model2.save_checkpoint(best_val_loss=0.001)\n",
    "model2_F.save_checkpoint(best_val_loss=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_animation(model=model1, test_set=test_setR1, feature_dims=feature_dims,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/TestAll_1_R1_One_1/False_2_0.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Replay/\"+model_name)\n",
    "generate_animation(model=model2, test_set=test_setR2, feature_dims=feature_dims2,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Test/R2.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Replay/\"+model_name2)\n",
    "generate_animation(model=model2_F, test_set=test_setR2, feature_dims=feature_dims2,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Test/R2.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Replay/\"+model_name2+\"F\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MLP MIX - Z as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config[\"z_dim\"]=128\n",
    "featureDim = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\":target_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims[\"pos\"],\n",
    "    \"rot_dim\":feature_dims[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "featureDim2 = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim2,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\": target_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims2[\"pos\"],\n",
    "    \"rot_dim\":feature_dims2[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims2[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "\n",
    "\n",
    "in_slice = [phase_dim, pose_dim, cost_dim, target_dim]\n",
    "in_slice2 = [phase_dim, pose_dim2, cost_dim,target_dim]\n",
    "\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "mlpmix_name1 = \"MLPMIX-R1-Z-Concat\"\n",
    "mlpmix1 = MLP_MIX(config=config, input_dims=[pose_dim])\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim], h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "mlpmix1.active_models[0] = temp\n",
    "mlpmix1.active_models[0].encoder.load_state_dict(ae1.encoder.state_dict())\n",
    "mlpmix1.active_models[0].decoder.load_state_dict(ae1.decoder.state_dict())\n",
    "\n",
    "pose_encoder = mlpmix1.active_models[0]\n",
    "middle_layer = mlpmix1.cluster_model\n",
    "pose_encoder.convDiscriminator.load_state_dict(ae1.convDiscriminator.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model1 = MoGenZ(config=config, Model=MoE_Z, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim, use_advLoss=True,\n",
    "                                 input_slicers=in_slice, output_slicers=out_slice,\n",
    "                                 train_set=train_setR1, val_set=val_setR1, test_set=test_setR1+val_setR1,\n",
    "                                 name=mlpmix_name1\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model1, mlpmix_name1, version=\"0.3\",MAX_EPOCHS=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlpmix_name2 = \"MLPMIX-R2-Z-Concat-Reduced\"\n",
    "mlpmix2 = MLP_MIX(config=config, input_dims=[pose_dim2])\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim2], h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "in_slice2 = [phase_dim, pose_dim2, cost_dim,target_dim]\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "temp.encoder.load_state_dict(ae2.encoder.state_dict())\n",
    "temp.decoder.load_state_dict(ae2.decoder.state_dict())\n",
    "\n",
    "pose_encoder = temp\n",
    "middle_layer = mlpmix2.cluster_model\n",
    "pose_encoder.convDiscriminator.load_state_dict(ae2.convDiscriminator.state_dict())\n",
    "\n",
    "middle_layer.load_state_dict(model1.middle_layer.state_dict())\n",
    "middle_layer.requires_grad_(False)\n",
    "\n",
    "\n",
    "model2 = MoGenZ(config=config, Model=MoE_Z, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim2,use_advLoss=True,\n",
    "                                 input_slicers=in_slice2, output_slicers=out_slice,\n",
    "                                 train_set=train_setR2, val_set=val_setR2, test_set=val_setR2+test_setR2,\n",
    "                                 name=mlpmix_name2\n",
    "                                   )\n",
    "\n",
    "model2.generationModel.gate.load_state_dict(model1.generationModel.gate.state_dict())\n",
    "model2.generationModel.load_state_dict(model1.generationModel.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model2, mlpmix_name2, version=\"0.2\", MAX_EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_checkpoints(os.path.join(MODEL_PATH,mlpmix_name1))\n",
    "clean_checkpoints(os.path.join(MODEL_PATH,mlpmix_name2))\n",
    "\n",
    "model1.save_checkpoint(best_val_loss=0.001)\n",
    "model2.save_checkpoint(best_val_loss=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_animation(model=model1, test_set=test_setR1, feature_dims=feature_dims,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/TestAll_1_R1_One_1/False_2_0.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/version0.3/\"+mlpmix_name1)\n",
    "generate_animation(model=model2, test_set=test_setR2, feature_dims=feature_dims2,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Test/R2.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/version0.3/\"+mlpmix_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RBF -  Z as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config[\"z_dim\"] = 256\n",
    "featureDim = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\":target_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims[\"pos\"],\n",
    "    \"rot_dim\":feature_dims[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "featureDim2 = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim2,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\": target_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims2[\"pos\"],\n",
    "    \"rot_dim\":feature_dims2[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims2[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "\n",
    "rbf_name1 = \"RBF-R1-Z-Concat\"\n",
    "rbf1 = RBF(config=config, input_dims=[pose_dim],\n",
    "           pos_dim=[featureDim[\"pos_dim\"]], rot_dim=[featureDim[\"rot_dim\"]], vel_dim=[featureDim[\"vel_dim\"]],\n",
    "           train_set=train_set_p1, val_set=val_set_p1, test_set=test_set_p1,\n",
    "           name=\"RBF-z-concat\")\n",
    "\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim], h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "rbf1.active_models[0] = temp\n",
    "rbf1.active_models[0].encoder.load_state_dict(ae1.encoder.state_dict())\n",
    "rbf1.active_models[0].decoder.load_state_dict(ae1.decoder.state_dict())\n",
    "rbf1.active_models[0].convDiscriminator.load_state_dict(ae1.convDiscriminator.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(rbf1, rbf_name1, version=\"0.1\", MAX_EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "in_slice = [phase_dim, pose_dim, cost_dim,target_dim]\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "pose_encoder = rbf1.active_models[0]\n",
    "middle_layer = rbf1.cluster_model\n",
    "middle_layer.requires_grad_(False)\n",
    "\n",
    "model1 = MoGenZ(config=config, Model=MoE_Z, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim, use_advLoss=True,\n",
    "                                 input_slicers=in_slice, output_slicers=out_slice,\n",
    "                                 train_set=train_setR1, val_set=val_setR1, test_set=test_setR1+val_setR1,\n",
    "                                 name=rbf_name1\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model1, rbf_name1, version=\"0.2\",MAX_EPOCHS=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rbf_name2 = \"RBF-R2-Z-Concat-Reduced\"\n",
    "rbf2 = RBF(config=config, input_dims=[pose_dim2])\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim2], h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "in_slice2 = [phase_dim, pose_dim2, cost_dim,target_dim]\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "rbf2.active_models[0] = temp\n",
    "rbf2.active_models[0].encoder.load_state_dict(ae2.encoder.state_dict())\n",
    "rbf2.active_models[0].decoder.load_state_dict(ae2.decoder.state_dict())\n",
    "\n",
    "pose_encoder = rbf2.active_models[0]\n",
    "middle_layer = rbf2.cluster_model\n",
    "pose_encoder.convDiscriminator.load_state_dict(ae2.convDiscriminator.state_dict())\n",
    "\n",
    "middle_layer.load_state_dict(model1.middle_layer.state_dict())\n",
    "middle_layer.requires_grad_(False)\n",
    "\n",
    "\n",
    "model2 = MoGenZ(config=config, Model=MoE_Z, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim2, use_advLoss=True,\n",
    "                                 input_slicers=in_slice2, output_slicers=out_slice,\n",
    "                                 train_set=train_setR2, val_set=val_setR2, test_set=val_setR2+test_setR2,\n",
    "                                 name=rbf_name2\n",
    "                                   )\n",
    "\n",
    "model2.generationModel.gate.load_state_dict(model1.generationModel.gate.state_dict())\n",
    "model2.generationModel.load_state_dict(model1.generationModel.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model2, rbf_name2, version=\"0.2\", MAX_EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_checkpoints(os.path.join(MODEL_PATH,rbf_name1))\n",
    "clean_checkpoints(os.path.join(MODEL_PATH,rbf_name2))\n",
    "\n",
    "model1.save_checkpoint(best_val_loss=0.001)\n",
    "model2.save_checkpoint(best_val_loss=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate_animation(model=model1, test_set=test_setR1, feature_dims=feature_dims,\n",
    "#                    template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/TestAll_1_R1_One_1/False_2_0.json\",\n",
    "#                    output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/version0.3/\"+rbf_name1)\n",
    "generate_animation(model=model2, test_set=test_setR2, feature_dims=feature_dims2,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Test/R2.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/version0.3/\"+rbf_name2+\"After\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# vae -  Z as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config[\"z_dim\"] = 256\n",
    "featureDim = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\":target_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims[\"pos\"],\n",
    "    \"rot_dim\":feature_dims[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "featureDim2 = {\n",
    "    \"phase_dim\": phase_dim,\n",
    "    \"pose_dim\": pose_dim2,\n",
    "    \"cost_dim\": cost_dim,\n",
    "    \"target_dim\": target_dim,\n",
    "    \"g_input_dim\": config[\"k\"] + config[\"cost_hidden_dim\"],\n",
    "    \"g_output_dim\":phase_dim + config[\"k\"] + cost_dim,\n",
    "    \"pos_dim\":feature_dims2[\"pos\"],\n",
    "    \"rot_dim\":feature_dims2[\"rotMat2\"],\n",
    "    \"vel_dim\":feature_dims2[\"velocity\"],\n",
    "    \"posCost\":feature_dims[\"posCost\"],\n",
    "    \"rotCost\":feature_dims[\"rotCost\"]\n",
    "    }\n",
    "\n",
    "vae_name1 = \"VAE-R1-Z-Concat\"\n",
    "vae1 = VAE(config=config, input_dims=[pose_dim],\n",
    "           pos_dim=[featureDim[\"pos_dim\"]], rot_dim=[featureDim[\"rot_dim\"]], vel_dim=[featureDim[\"vel_dim\"]],\n",
    "           train_set=train_set_p1, val_set=val_set_p1, test_set=test_set_p1,\n",
    "           name=\"VAE-z-concat\")\n",
    "\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim], h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "vae1.active_models[0] = temp\n",
    "vae1.active_models[0].encoder.load_state_dict(ae1.encoder.state_dict())\n",
    "vae1.active_models[0].decoder.load_state_dict(ae1.decoder.state_dict())\n",
    "vae1.active_models[0].convDiscriminator.load_state_dict(ae1.convDiscriminator.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(vae1, vae_name1, version=\"0.1\", MAX_EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "in_slice = [phase_dim, pose_dim, cost_dim,target_dim]\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "pose_encoder = vae1.active_models[0]\n",
    "middle_layer = vae1.cluster_model\n",
    "middle_layer.requires_grad_(False)\n",
    "\n",
    "model1 = MoGenVAE_Z(config=config, Model=MoE_Z, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim, use_advLoss=True,\n",
    "                                 input_slicers=in_slice, output_slicers=out_slice,\n",
    "                                 train_set=train_setR1, val_set=val_setR1, test_set=test_setR1+val_setR1,\n",
    "                                 name=vae_name1\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model1, vae_name1, version=\"0.1\",MAX_EPOCHS=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vae_name2 = \"VAE-R2-Z-Concat-Reduced\"\n",
    "vae2 = VAE(config=config, input_dims=[pose_dim2])\n",
    "temp = MLP_ADV(config=config, dimensions=[pose_dim2], h_dim=h_dim, w_dim=w_dim,)\n",
    "\n",
    "in_slice2 = [phase_dim, pose_dim2, cost_dim,target_dim]\n",
    "out_slice = [phase_dim, config[\"k\"], cost_dim]\n",
    "\n",
    "vae2.active_models[0] = temp\n",
    "vae2.active_models[0].encoder.load_state_dict(ae2.encoder.state_dict())\n",
    "vae2.active_models[0].decoder.load_state_dict(ae2.decoder.state_dict())\n",
    "\n",
    "pose_encoder = vae2.active_models[0]\n",
    "middle_layer = vae2.cluster_model\n",
    "pose_encoder.convDiscriminator.load_state_dict(ae2.convDiscriminator.state_dict())\n",
    "\n",
    "middle_layer.load_state_dict(model1.middle_layer.state_dict())\n",
    "middle_layer.requires_grad_(False)\n",
    "\n",
    "\n",
    "model2 = MoGenVAE_Z(config=config, Model=MoE_Z, pose_autoencoder=pose_encoder, middle_layer=middle_layer,\n",
    "                                 feature_dims=featureDim2, use_advLoss=True,\n",
    "                                 input_slicers=in_slice2, output_slicers=out_slice,\n",
    "                                 train_set=train_setR2, val_set=val_setR2, test_set=val_setR2+test_setR2,\n",
    "                                 name=vae_name2\n",
    "                                   )\n",
    "\n",
    "model2.generationModel.gate.load_state_dict(model1.generationModel.gate.state_dict())\n",
    "model2.generationModel.load_state_dict(model1.generationModel.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fit(model2, vae_name2, version=\"0.3\", MAX_EPOCHS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_checkpoints(os.path.join(MODEL_PATH,vae_name1))\n",
    "clean_checkpoints(os.path.join(MODEL_PATH,vae_name2))\n",
    "\n",
    "model1.save_checkpoint(best_val_loss=0.001)\n",
    "model2.save_checkpoint(best_val_loss=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_animation(model=model1, test_set=test_setR1, feature_dims=feature_dims, use_vae=True,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/TestAll_1_R1_One_1/False_2_0.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/version0.3/\"+vae_name1)\n",
    "generate_animation(model=model2, test_set=test_setR2, feature_dims=feature_dims2,use_vae=True,\n",
    "                   template_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/Test/R2.json\",\n",
    "                   output_path=\"/home/nuoc/.config/unity3d/DefaultCompany/Procedural Animation/version0.3/\"+vae_name2+\"After\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%d\n"
    }
   },
   "outputs": [],
   "source": [
    "def setVec3(struct, vec):\n",
    "    struct[\"x\"] = vec[0].item()\n",
    "    struct[\"y\"] = vec[1].item()\n",
    "    struct[\"z\"] = vec[2].item()\n",
    "\n",
    "def setVec6(struct, vec):\n",
    "    for r, cell in enumerate([\"x\", \"y\", \"z\"]):\n",
    "        for col, column in enumerate([\"c0\", \"c1\"]):\n",
    "            struct[column][cell] = vec[r, col].item()\n",
    "\n",
    "def insert_pos(template,\n",
    "               positions=None, rotations=None, velocity=None,\n",
    "               tPos=None, tRot=None, name=\"Replay\"):\n",
    "    shape = positions.shape\n",
    "    for c in range(shape[0]):\n",
    "        for f in range(shape[1]):\n",
    "            t = 0\n",
    "            for j in range(shape[2]):\n",
    "                jo = template[\"frames\"][f][\"joints\"][j]\n",
    "                if positions is not None:\n",
    "                    setVec3(jo[\"position\"], positions[c,f,j])\n",
    "                if rotations is not None:\n",
    "                    setVec3(jo[\"velocity\"], velocity[c,f,j])\n",
    "                if velocity is not None:\n",
    "                    setVec6(jo[\"rotMat\"], rotations[c,f,j])\n",
    "\n",
    "\n",
    "                if jo[\"key\"]:\n",
    "                    if tPos is not None:\n",
    "                        setVec3(jo[\"cost\"][\"TargetPosition\"], tPos[c,f,t])\n",
    "                    if tRot is not None:\n",
    "                        setVec6(jo[\"cost\"][\"TargetRotation\"], tRot[c,f,t])\n",
    "                    t+=1\n",
    "        with open(\"{}_{}.json\".format(name, c), \"w\") as f:\n",
    "            js.dump(template, f)\n",
    "\n",
    "def generate_animation(model, test_set, feature_dims, template_path, output_path, use_vae=False, n=5):\n",
    "    idx = np.arange(n)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.cpu()\n",
    "        model.pose_autoencoder.encoder.eval()\n",
    "        model.pose_autoencoder.decoder.eval()\n",
    "        model.generationModel.eval()\n",
    "\n",
    "        x = torch.stack([test_set[i][0] for i in idx])\n",
    "        y = torch.stack([test_set[i][1] for i in idx])\n",
    "        shape = x.shape\n",
    "        x = x.view(-1, shape[-1])\n",
    "\n",
    "        x.cpu()\n",
    "        if use_vae:\n",
    "            out, z, mu, logvar = model(x)\n",
    "        else:\n",
    "            out = model(x)\n",
    "        x_c = torch.cat(out,dim=1).detach()\n",
    "        generated = x_c\n",
    "        generated = generated.view(shape)\n",
    "\n",
    "    phase= feature_dims[\"phase_vec_l2\"]\n",
    "    toPosDim = phase+feature_dims[\"pos\"]\n",
    "    toRotDim = toPosDim + feature_dims[\"rotMat2\"]\n",
    "    toVelDim = toRotDim + feature_dims[\"velocity\"]\n",
    "\n",
    "    gPos = generated[:, :, phase:toPosDim]\n",
    "    gRot = generated[:, :, toPosDim:toRotDim]\n",
    "    gVel = generated[:, :, toRotDim:toVelDim]\n",
    "\n",
    "    oPos = y[:, :, phase:toPosDim]\n",
    "    oRot = y[:, :, toPosDim:toRotDim]\n",
    "    oVel = y[:, :, toRotDim:toVelDim]\n",
    "\n",
    "    tPos = y[:, :, -target_dim:-target_dim+3*4]\n",
    "    tRot = y[:, :, -target_dim+3*4:]\n",
    "\n",
    "    print(gPos.shape, gRot.shape, gVel.shape)\n",
    "    print(oPos.shape, oRot.shape, oVel.shape)\n",
    "\n",
    "    clip_length = gPos.shape[1]\n",
    "    gPos_r = gPos.reshape((n, clip_length, -1, 3))\n",
    "    gRot_r = gRot.reshape((n, clip_length, -1, 3, 2))\n",
    "    gVel_r = gVel.reshape((n, clip_length, -1, 3))\n",
    "\n",
    "    oPos_r = oPos.reshape((n, clip_length, -1, 3))\n",
    "    oRot_r = oRot.reshape((n, clip_length, -1, 3, 2))\n",
    "    oVel_r = oVel.reshape((n, clip_length, -1, 3))\n",
    "\n",
    "    tPos_r = tPos.reshape((n, clip_length, -1, 3))\n",
    "    tRot_r = tRot.reshape((n, clip_length, -1, 3, 3))\n",
    "\n",
    "    template = js.load(open(template_path))\n",
    "\n",
    "    insert_pos(template, oPos_r, oRot_r, oVel_r, tPos_r, tRot_r,output_path+\"_O\")\n",
    "    insert_pos(template, gPos_r, gRot_r, gVel_r, tPos_r, tRot_r,output_path+\"_G\")\n",
    "\n",
    "def generate_animation_ae(model, test_set, feature_dims, template_path, output_path, n=5):\n",
    "    idx = np.arange(n)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.cpu()\n",
    "\n",
    "        x = torch.stack([test_set[i][0] for i in idx])\n",
    "        y = torch.stack([test_set[i][1] for i in idx])\n",
    "        shape = x.shape\n",
    "        x = x.view(-1, shape[-1])\n",
    "\n",
    "        x.cpu()\n",
    "        out = model(x)\n",
    "\n",
    "        generated = out\n",
    "        generated = generated.view(shape)\n",
    "\n",
    "    toPosDim = feature_dims[\"pos\"]\n",
    "    toRotDim = toPosDim + feature_dims[\"rotMat2\"]\n",
    "    toVelDim = toRotDim + feature_dims[\"velocity\"]\n",
    "\n",
    "    gPos = generated[:, :, :toPosDim]\n",
    "    gRot = generated[:, :, toPosDim:toRotDim]\n",
    "    gVel = generated[:, :, toRotDim:toVelDim]\n",
    "\n",
    "    oPos = y[:, :, :toPosDim]\n",
    "    oRot = y[:, :, toPosDim:toRotDim]\n",
    "    oVel = y[:, :, toRotDim:toVelDim]\n",
    "\n",
    "    print(gPos.shape, gRot.shape, gVel.shape)\n",
    "    print(oPos.shape, oRot.shape, oVel.shape)\n",
    "\n",
    "    clip_length = gPos.shape[1]\n",
    "    gPos_r = gPos.reshape((n, clip_length, -1, 3))\n",
    "    gRot_r = gRot.reshape((n, clip_length, -1, 3, 2))\n",
    "    gVel_r = gVel.reshape((n, clip_length, -1, 3))\n",
    "\n",
    "    oPos_r = oPos.reshape((n, clip_length, -1, 3))\n",
    "    oRot_r = oRot.reshape((n, clip_length, -1, 3, 2))\n",
    "    oVel_r = oVel.reshape((n, clip_length, -1, 3))\n",
    "\n",
    "    template = js.load(open(template_path))\n",
    "\n",
    "    insert_pos(template, oPos_r, oRot_r, oVel_r, None, None,output_path+\"_O\")\n",
    "    insert_pos(template, gPos_r, gRot_r, gVel_r, None, None, output_path+\"_G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
