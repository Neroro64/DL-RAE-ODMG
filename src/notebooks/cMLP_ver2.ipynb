{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, time\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "import json as js\n",
    "import _pickle as pickle\n",
    "import bz2\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from collections import OrderedDict\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "import shutil\n",
    "import tempfile\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, \\\n",
    "    TuneReportCheckpointCallback\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from cytoolz import sliding_window\n",
    "sys.path.append(\"../\")\n",
    "import func"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple MLP Autoencoder\n",
    "$\n",
    "f(x,\\theta) = dec(enc(x,\\theta_1), \\theta_2) = x,   \\quad \\theta = (\\theta_1, \\theta_2)\n",
    "$\n",
    "\n",
    "$\n",
    "enc(x, \\theta_1) = z, \\quad   z \\in Z \\quad \\text{ = latent space}\n",
    "$\n",
    "\n",
    "$\n",
    "dec(z, \\theta_2) = x, \\quad   x \\in X \\quad \\text{ = input space}\n",
    "$\n",
    "\n",
    "This model uses simple Multi-layered perceptron (MLP) for both encoder and decoder.\n",
    "\n",
    "$\n",
    "enc = dec = mlp(X, \\theta), \\quad \\theta = W, b\n",
    "\n",
    "$\n",
    "mlp(X, W) = f(f(X \\cdot w_1 + b_1) \\cdot w_2 + b_2) \\cdot w_3 + b_3\n",
    "$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dimensions:list, act_fn:str, keep_prob:float=.2, batch_size:int=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dimensions = dimensions          #   [(in, h1), (h1, h2), ..., (hn, out)]\n",
    "        self.act= act_fn                     #   func\n",
    "        self.keep_prob = keep_prob          #   %\n",
    "        self.batch_size = batch_size        #   int\n",
    "\n",
    "        self.model = []\n",
    "\n",
    "        assert(len(dimensions) >= 2)\n",
    "        assert(batch_size > 0)\n",
    "        assert(act_fn == \"elu\" or act_fn == \"relu\")\n",
    "        assert(keep_prob < 1)\n",
    "        for e in dimensions: assert(type(e) == int)\n",
    "\n",
    "        self.build()\n",
    "        self.model.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        for i, size in enumerate(zip(self.dimensions[0:], self.dimensions[1:])):\n",
    "            layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "            if i < len(self.dimensions)-2:\n",
    "                layers.append((\"act\"+str(i), self.activation(self.act)))\n",
    "                layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "\n",
    "        self.model = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    " \n",
    "    @staticmethod\n",
    "    def activation(fn_name):\n",
    "        if fn_name == \"elu\":\n",
    "            return nn.ELU()\n",
    "        elif fn_name == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        else:\n",
    "            return nn.ReLU()\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MLP_AE(nn.Module):\n",
    "    def __init__(self, encoder:nn.Module, decoder:nn.Module):\n",
    "        super(MLP_AE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def loadFeatures(data, feature_list):\n",
    "    data = pickle.loads(data)\n",
    "    features = []\n",
    "    for f in data[\"frames\"]:\n",
    "        p = []\n",
    "        for feature in feature_list:\n",
    "            if feature == \"rotMat\":\n",
    "                p.append(np.concatenate([jo[\"rotMat\"].ravel() for jo in f]))\n",
    "            else:\n",
    "                p.append(np.concatenate([jo[feature] for jo in f]))\n",
    "\n",
    "        p = np.concatenate(p)\n",
    "        features.append(p)\n",
    "    return np.vstack(features)\n",
    "\n",
    "def processData(compressed_data, feature_list, num_cpus=24):\n",
    "    ray.init(num_cpus=num_cpus,ignore_reinit_error=True)\n",
    "    data = [loadFeatures.remote(d, feature_list) for d in compressed_data]\n",
    "    data = [ray.get(d) for d in data]\n",
    "    ray.shutdown()\n",
    "    return data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-3f4f8ee50bd2>\", line 6, in <module>\n",
      "    input_data = np.vstack(d)\n",
      "NameError: name 'd' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/nuoc/miniconda3/lib/python3.8/posixpath.py\", line 170, in islink\n",
      "    return stat.S_ISLNK(st.st_mode)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# preparing data loaders\n",
    "data_ratio = (.7, .15, .15) # training, validation, testing\n",
    "SEED = 2021\n",
    "batch_size = 10\n",
    "input_data = np.vstack(d)\n",
    "# x_tensor = torch.from_numpy(input_data).float().to(device)\n",
    "# y_tensor = torch.from_numpy(input_data).float().to(device)\n",
    "\n",
    "x_tensor = torch.from_numpy(input_data).float()\n",
    "y_tensor = torch.from_numpy(input_data).float()\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "N = len(dataset)\n",
    "\n",
    "train_ratio = int(data_ratio[0]*N)\n",
    "val_ratio = int(data_ratio[1] * N)\n",
    "test_ratio = int(N-train_ratio-val_ratio)\n",
    "print(\"Train: \", train_ratio, \", Validation: \", val_ratio, \", Test: \", test_ratio)\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, num_epochs, device,\n",
    "          data_loaders=None, n_epochs_no_improve=10, verbose=True,\n",
    "          save_model=False, save_path=\"../../models/best_model\",\n",
    "          use_tune=False):\n",
    "    np.random.seed(SEED)\n",
    "    torch.random.manual_seed(SEED)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    train_loader, val_loader, test_loader = data_loaders\n",
    "    total_step = len(train_loader)\n",
    "    i = 0\n",
    "\n",
    "    train_loader_len = float(len(train_loader))\n",
    "    val_loader_len = float(len(val_loader))\n",
    "    test_loader_len = float(len(test_loader))\n",
    "\n",
    "    last_avg_training_loss = 0\n",
    "    min_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "    best_model_after_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        training_loss = 0\n",
    "        # training\n",
    "        for inputs, outputs in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, outputs)\n",
    "            training_loss+=loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        last_avg_training_loss = training_loss / train_loader_len\n",
    "        if verbose:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                .format(epoch+1, num_epochs, last_avg_training_loss))\n",
    "\n",
    "        # early stopping\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for inputs, outputs in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = outputs.to(device)\n",
    "\n",
    "                pred_val = model(inputs)\n",
    "                loss_val = criterion(pred_val, outputs)\n",
    "                val_loss += loss_val.item()\n",
    "\n",
    "            val_loss /= val_loader_len\n",
    "            if min_loss > val_loss:\n",
    "                min_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                best_model_after_epoch = epoch\n",
    "                if save_model:\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "            else:\n",
    "                epochs_no_improve+=1\n",
    "                if epochs_no_improve > n_epochs_no_improve and verbose:\n",
    "                    print(\"Early stopping at Epoch: \", epoch)\n",
    "                    print(\"last training loss: {:2f}\".format(last_avg_training_loss))\n",
    "                    print(\"achieved best validation loss: {:.4f} after at Epoch {}\".format(min_loss, best_model_after_epoch))\n",
    "                    break\n",
    "            if use_tune:\n",
    "                tune.report(iterations=epoch, mean_loss=val_loss)\n",
    "    # Testing\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for inputs, outputs in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            pred_test = model(inputs)\n",
    "            loss_test = criterion(pred_test, outputs)\n",
    "            test_loss += loss_test.item()\n",
    "\n",
    "        test_loss /= test_loader_len\n",
    "        if verbose:\n",
    "            print(\"Test loss: {:.4f}\".format(test_loss))\n",
    "        if use_tune:\n",
    "            tune.report(iterations=epoch, mean_loss=test_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test Ray Tune for hyperparameter tuning\n",
    "input_dim = input_data.shape[1]\n",
    "output_dim = input_data.shape[1]\n",
    "k = 10\n",
    "latent_dim = k * (3 + 9 + 3)         # 12 * 3\n",
    "encoder_layer_sizes = [input_dim, 256, 256, latent_dim]\n",
    "decoder_layer_sizes = [latent_dim, 256, 256, output_dim]\n",
    "num_epochs = 300\n",
    "act_fn = \"elu\"\n",
    "keep_prob = .2\n",
    "\n",
    "\n",
    "\n",
    "def trainable(config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    latent_dim = int(config[\"k\"])\n",
    "    encoder_layer_sizes = [input_dim, 256, 256, latent_dim]\n",
    "    decoder_layer_sizes = [latent_dim, 256, 256, output_dim]\n",
    "    encoder = MLP(encoder_layer_sizes, act_fn, keep_prob, batch_size)\n",
    "    decoder = MLP(decoder_layer_sizes, act_fn, keep_prob, batch_size)\n",
    "    model = MLP_AE(encoder, decoder)\n",
    "\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.95)\n",
    "    train(model, criterion, optimizer, scheduler, num_epochs, device=device,\n",
    "          data_loaders=(train_loader, val_loader, test_loader),verbose=False, use_tune=True)\n",
    "\n",
    "search_space= {\n",
    "    \"k\" : tune.randint(3, 125),\n",
    "    \"lr\" : tune.uniform(1e-3, 1e-9)\n",
    "}\n",
    "\n",
    "# bayesopt = BayesOptSearch(metric=\"mean_loss\", mode=\"min\")\n",
    "trial_scheduler = ray.tune.schedulers.ASHAScheduler(grace_period=5, max_t = 100)\n",
    "tune.run(trainable, config=search_space, scheduler=trial_scheduler, metric=\"mean_loss\", mode=\"min\",\n",
    "         resources_per_trial={\"cpu\":12, \"gpu\":1},\n",
    "         num_samples=20, stop={\"training_iteration\":20})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Test torch lightning + ray tune\n",
    "\n",
    "class MLP2(pl.LightningModule):\n",
    "    def __init__(self, config, dimensions:list,  loss_fn=None,\n",
    "                 dataset=None, train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name=\"model\"):\n",
    "\n",
    "        super(MLP2, self).__init__()\n",
    "        self.name = name\n",
    "\n",
    "        self.k = config[\"k\"]\n",
    "        self.learning_rate = config[\"lr\"]\n",
    "        dimensions.append(self.k)\n",
    "        self.dimensions = dimensions\n",
    "        self.loss_fn = loss_fn\n",
    "        self.keep_prob = keep_prob          #   %\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.train_set = train_set\n",
    "        self.val_set = val_set\n",
    "        self.test_set = test_set\n",
    "        self.best_val_loss = np.inf\n",
    "\n",
    "        self.build()\n",
    "        if self.train_set is None:\n",
    "            self.setup_data([.7, .15, .15])\n",
    "\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(self).__init__()\n",
    "        self.encoder.load_state_dict()\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "\n",
    "        for i, size in enumerate(layer_sizes):\n",
    "            layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "            if i < len(self.dimensions)-2:\n",
    "                layers.append((\"act\"+str(i), nn.ELU()))\n",
    "                layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "        self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "        layers = []\n",
    "        for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "            layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "            if i < len(self.dimensions)-2:\n",
    "                layers.append((\"act\"+str(i), nn.ELU()))\n",
    "                layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "        self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint()\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir=\"/home/nuoc/checkpoints\"):\n",
    "        # model = {\"encoder\": self.encoder.state_dict(), \"decoder\": self.decoder.state_dict()}\n",
    "        # with bz2.BZ2File(os.path.join(checkpoint_dir, self.name+str(self.best_val_loss.cpu().numpy())+\".pbz2\"), \"w\") as f:\n",
    "        #     pickle.dump(model, f)\n",
    "        torch.save(self, os.path.join(checkpoint_dir, self.name, str(self.best_val_loss.cpu().numpy())))\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filename, checkpoint_dir=\"/home/nuoc/checkpoints\"):\n",
    "        return torch.load(os.path.join(checkpoint_dir,filename))\n",
    "        # with bz2.BZ2File(os.path.join(checkpoint_dir, self.name+\"pbz2\"), \"rb\") as f:\n",
    "        #     obj = pickle.load(f)\n",
    "        # self.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        # self.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        # self.best_val_loss = obj[\"val_loss\"]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self, split_ratio):\n",
    "        self.n_train_samples= int(split_ratio[0]*N)\n",
    "        self.n_val_samples= int(split_ratio[1] * N)\n",
    "        self.n_test_samples= int(N-self.n_train_samples-self.n_val_samples)\n",
    "        self.train_set, self.val_set, self.test_set = random_split(self.dataset,\n",
    "                                                                   [self.n_train_samples,\n",
    "                                                                    self.n_val_samples,\n",
    "                                                                    self.n_test_samples])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def train_tune(config, dimensions:list,  loss_fn=None,\n",
    "                 dataset=None, train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, num_epochs=300, num_cpus=24, num_gpus=1, model_name=\"model\"):\n",
    "    model = MLP2(config, dimensions, loss_fn, dataset, train_set, val_set, test_set, keep_prob, name=model_name)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,\n",
    "        gpus=num_gpus,\n",
    "        logger=TensorBoardLogger(save_dir=\"logs/\", name=\"test\", version=\"0.0\"),\n",
    "        progress_bar_refresh_rate=20,\n",
    "        callbacks=[\n",
    "            TuneReportCallback({\"loss\":\"avg_val_loss\",}, on=\"validation_end\"),\n",
    "            EarlyStopping(monitor=\"avg_val_loss\")\n",
    "        ],\n",
    "        precision=16,\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "\n",
    "def normalise(x:torch.Tensor):\n",
    "    std = torch.std(x)\n",
    "    std[std==0] = 1\n",
    "    return (x - torch.mean(x)) / std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Prepare train data\n",
    "data_path = \"../../data/\"\n",
    "\n",
    "# load data\n",
    "data_1 = func.load(data_path+\"LOCO_R2-default-locomotion.pbz2\")\n",
    "data_2 = func.load(data_path+\"LOCO_R2-default-locomotion-small.pbz2\")\n",
    "data_3 = func.load(data_path+\"LOCO_R2-default-locomotion-large.pbz2\")\n",
    "# data = data_1 + data_2 + data_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 12:32:46,220\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2021-03-30 12:32:50,299\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2021-03-30 12:32:54,258\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "dS = processData(data_1, [\"pos\", \"rotMat\", \"velocity\"])\n",
    "dN = processData(data_2, [\"pos\", \"rotMat\", \"velocity\"])\n",
    "dL = processData(data_3, [\"pos\", \"rotMat\", \"velocity\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "data_ratio = (.8, .2) # training, validation, testing\n",
    "SEED = 2021\n",
    "batch_size = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "input_dataN = np.vstack(dS)\n",
    "input_dataS = np.vstack(dN)\n",
    "input_dataL = np.vstack(dL)\n",
    "\n",
    "x_tensorN = normalise(torch.from_numpy(input_dataN).float())\n",
    "x_tensorS = normalise(torch.from_numpy(input_dataS).float())\n",
    "x_tensorL = normalise(torch.from_numpy(input_dataL).float())\n",
    "\n",
    "y_tensorN = torch.from_numpy(input_dataN).float()\n",
    "y_tensorS = torch.from_numpy(input_dataS).float()\n",
    "y_tensorL = torch.from_numpy(input_dataL).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_setN = (x_tensorN[-100:], y_tensorN[-100:])\n",
    "test_setS = (x_tensorS[-100:], y_tensorS[-100:])\n",
    "test_setL = (x_tensorL[-100:], y_tensorL[-100:])\n",
    "\n",
    "x_tensor = torch.vstack((x_tensorN[:-100],x_tensorS[:-100],x_tensorL[:-100]))\n",
    "y_tensor = torch.vstack((y_tensorN[:-100],y_tensorS[:-100],y_tensorL[:-100]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  3216 , Validation:  804\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "N = len(dataset)\n",
    "\n",
    "train_ratio = int(data_ratio[0]*N)\n",
    "val_ratio = int(data_ratio[1] * N)\n",
    "print(\"Train: \", train_ratio, \", Validation: \", val_ratio)\n",
    "\n",
    "train_set, val_set = random_split(dataset, [train_ratio, val_ratio], generator=torch.Generator().manual_seed(SEED))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "input_dim = x_tensor.size()[1]\n",
    "output_dim = input_dim\n",
    "\n",
    "dimensions = [input_dim, 256]\n",
    "loss_fn = F.mse_loss\n",
    "keep_prob = .2\n",
    "\n",
    "num_gpus = 1\n",
    "num_samples = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'k': 80, 'lr': 3.735665209326538e-05, 'batch_size': 48}\n",
      "Best achieved loss was:  {'loss': 0.001535896211862564, 'time_this_iter_s': 0.1661853790283203, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 145, 'experiment_id': '39af078703df4cd4954038ba62d51137', 'date': '2021-03-30_13-00-15', 'timestamp': 1617102015, 'time_total_s': 32.45197796821594, 'pid': 539097, 'hostname': 'Desktop', 'node_ip': '192.168.1.35', 'config': {'k': 80, 'lr': 3.735665209326538e-05, 'batch_size': 48}, 'time_since_restore': 32.45197796821594, 'timesteps_since_restore': 0, 'iterations_since_restore': 145, 'trial_id': '9ae0f_00009', 'experiment_tag': '9_batch_size=48,k=80,lr=3.7357e-05'}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"k\":tune.randint(2, 256),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-7),\n",
    "    \"batch_size\":tune.choice([12, 24, 48])\n",
    "}\n",
    "scheduler = ASHAScheduler(max_t = EPOCHS, grace_period=1, reduction_factor=2)\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=[\"k\", \"lr\", \"batch_size\"],\n",
    "    metric_columns=[\"loss\", \"training_iteration\"])\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(\n",
    "        train_tune,\n",
    "        dimensions = dimensions,\n",
    "        loss_fn = loss_fn,\n",
    "        train_set = train_set, val_set = val_set, test_set=[test_setN,test_setS, test_setL],\n",
    "        keep_prob = keep_prob,\n",
    "        num_epochs = EPOCHS,\n",
    "        num_gpus=num_gpus,\n",
    "        model_name=\"MLP-MLP\"\n",
    "    ),\n",
    "    resources_per_trial= {\"cpu\":1, \"gpu\":num_gpus},\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=\"MLP-MLP\",\n",
    "    verbose=0,\n",
    "    checkpoint_freq=0,\n",
    "    keep_checkpoints_num=1,\n",
    "    checkpoint_score_attr=\"loss\",\n",
    "    checkpoint_at_end=True\n",
    ")\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "print(\"Best achieved loss was: \", analysis.best_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "checkpoint = analysis.best_checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nuoc/ray_results/MLP-MLP/_inner_7f85a_00000_0_batch_size=16,k=210,lr=7.709e-05_2021-03-30_12-48-44/checkpoint_-1/\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "obj = func.load(\"/home/nuoc/checkpoints/MLP-MLP.pbz2\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "'0.81520677'"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(obj[\"val_loss\"].cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n",
      "['MLP-MLP0', '0017080612', 'pbz2']\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/nuoc/checkpoints\"\n",
    "saved_checkpoints = []\n",
    "for dname, dirs, files in os.walk(path):\n",
    "    for fname in files:\n",
    "        fname = fname.split(\".\")\n",
    "        saved_checkpoints.append(fname)\n",
    "\n",
    "print(len(saved_checkpoints))\n",
    "print(saved_checkpoints[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "saved_checkpoints.sort(key = lambda x: x[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "for filename in saved_checkpoints[3:]:\n",
    "    os.remove(os.path.join(path, \".\".join(filename)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "'MLP-MLP0.001391014.pbz2'"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = saved_checkpoints[0]\n",
    "l = \".\".join(l)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "obj = func.load(\"/home/nuoc/checkpoints/MLP-MLP0.001391014.pbz2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.cuda.FloatTensor is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-64-84a243f89615>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# model = MLP2(None,[])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mencoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSequential\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"encoder\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mdecoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSequential\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"decoder\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36madd_module\u001B[0;34m(self, name, module)\u001B[0m\n\u001B[1;32m    370\u001B[0m         \"\"\"\n\u001B[1;32m    371\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mModule\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 372\u001B[0;31m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001B[0m\u001B[1;32m    373\u001B[0m                 torch.typename(module)))\n\u001B[1;32m    374\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_six\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstring_classes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: torch.cuda.FloatTensor is not a Module subclass"
     ]
    }
   ],
   "source": [
    "# model = MLP2(None,[])\n",
    "encoder = nn.Sequential(obj[\"encoder\"])\n",
    "decoder = nn.Sequential(obj[\"decoder\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}