{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, time\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "import json as js\n",
    "import _pickle as pickle\n",
    "import bz2\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from collections import OrderedDict\n",
    "from cytoolz import sliding_window, accumulate\n",
    "import pytorch_lightning as pl\n",
    "from operator import add\n",
    "from tabulate import tabulate\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../rig_agnostic_encoding\")\n",
    "sys.path.append(\"../rig_agnostic_encoding/models\")\n",
    "sys.path.append(\"../rig_agnostic_encoding/functions\")\n",
    "import func\n",
    "# from MLP_withLabel import MLP_withLabel\n",
    "# from MLP import MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/nuoc/Documents/MEX/data\"\n",
    "MODEL_PATH = \"/home/nuoc/Documents/MEX/models\"\n",
    "RESULTS_PATH = \"/home/nuoc/Documents/MEX/results\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MLP_withLabel(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, dimensions:list=None, extra_feature_len:int=0,\n",
    "                 train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name:str=\"model\", load=False,\n",
    "                 single_module:int=0):\n",
    "\n",
    "        super(MLP_withLabel, self).__init__()\n",
    "        self.name = name\n",
    "        self.dimensions = dimensions\n",
    "        self.keep_prob = keep_prob\n",
    "        self.single_module = single_module\n",
    "        self.extra_feature_len = extra_feature_len\n",
    "        self.act = nn.ELU\n",
    "        self.k = 0\n",
    "        if load:\n",
    "            self.build()\n",
    "        else:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.k = config[\"k\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.act = config[\"activation\"]\n",
    "            self.loss_fn = config[\"ae_loss_fn\"]\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "            self.dimensions = [self.dimensions[0]-extra_feature_len, self.hidden_dim, self.k]\n",
    "            self.train_set = train_set\n",
    "            self.val_set = val_set\n",
    "            self.test_set = test_set\n",
    "\n",
    "            self.best_val_loss = np.inf\n",
    "\n",
    "        self.build()\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "        if self.single_module == -1 or self.single_module == 0:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.encoder = nn.Sequential()\n",
    "\n",
    "        if self.single_module == 0 or self.single_module == 1:\n",
    "            layers = []\n",
    "            layer_sizes[-1] = (layer_sizes[-1][0], layer_sizes[-1][1] + self.extra_feature_len)\n",
    "            for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decode(*self.encode(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        _x, label = x[:, :-self.extra_feature_len], x[:, -self.extra_feature_len:]\n",
    "        h = self.encoder(_x)\n",
    "        return h, label\n",
    "\n",
    "    def decode(self, h, label):\n",
    "        hr = torch.cat((h, label), dim=1)\n",
    "        return self.decoder(hr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(best_val_loss=self.best_val_loss.cpu().numpy())\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"k\":self.k, \"dimensions\":self.dimensions,\"keep_prob\":self.keep_prob, \"name\":self.name,\n",
    "                 \"extra_feature_len\" : self.extra_feature_len,\n",
    "                 \"encoder\":self.encoder.state_dict(),\n",
    "                 \"decoder\":self.decoder.state_dict()}\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".\"+str(self.k)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MLP_withLabel(name=obj[\"name\"], dimensions=obj[\"dimensions\"], extra_feature_len=obj[\"extra_feature_len\"], keep_prob=obj[\"keep_prob\"], load=True)\n",
    "        model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, dimensions:list=None,\n",
    "                 train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name:str=\"model\", load=False,\n",
    "                 single_module:int=0):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        self.name = name\n",
    "        self.dimensions = dimensions\n",
    "        self.keep_prob = keep_prob\n",
    "        self.single_module = single_module\n",
    "        self.act = nn.ELU\n",
    "        self.k = 0\n",
    "        if load:\n",
    "            self.build()\n",
    "        else:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.k = config[\"k\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.act = config[\"activation\"]\n",
    "            self.loss_fn = config[\"loss_fn\"]\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "            self.dimensions = dimensions + [self.hidden_dim, self.k]\n",
    "            self.train_set = train_set\n",
    "            self.val_set = val_set\n",
    "            self.test_set = test_set\n",
    "\n",
    "            self.best_val_loss = np.inf\n",
    "\n",
    "            self.build()\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "        if self.single_module == -1 or self.single_module == 0:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.encoder = nn.Sequential()\n",
    "\n",
    "        if self.single_module == 0 or self.single_module == 1:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(best_val_loss=self.best_val_loss.cpu().numpy())\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"k\":self.k, \"dimensions\":self.dimensions,\"keep_prob\":self.keep_prob, \"name\":self.name,\n",
    "                 \"single_module\":self.single_module,\n",
    "                 \"encoder\":self.encoder.state_dict(),\n",
    "                 \"decoder\":self.decoder.state_dict()}\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".\"+str(self.k)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MLP(name=obj[\"name\"], dimensions=obj[\"dimensions\"], keep_prob=obj[\"keep_prob\"],\n",
    "                  load=True)\n",
    "        model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        # model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class MoE(nn.Module):\n",
    "    def __init__(self, config=None, dimensions=None, phase_input_dim:int=0,\n",
    "                 gate_size=0, k_experts=1, keep_prob=.2,\n",
    "                 name=\"model\", load=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.phase_input_dim = phase_input_dim\n",
    "        self.dimensions = dimensions\n",
    "        self.act_fn = nn.ELU\n",
    "        self.name = name\n",
    "        self.config=config\n",
    "        self.gate_size=gate_size\n",
    "        self.k_experts = k_experts\n",
    "        self.keep_prob = .2\n",
    "        if not load:\n",
    "            self.k_experts = config[\"k_experts\"]\n",
    "            self.gate_size = config[\"gate_size\"]\n",
    "            self.keep_prob = config[\"keep_prob\"]\n",
    "            self.dimensions = [self.dimensions[0], config[\"hidden_dim\"], config[\"hidden_dim\"], self.dimensions[-1]]\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        self.build()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(phase_input_dim, self.gate_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.gate_size, self.gate_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.gate_size, self.k_experts)\n",
    "        )\n",
    "        self.init_params()\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor, phase) -> torch.Tensor:\n",
    "        coefficients = F.softmax(self.gate(phase), dim=1)\n",
    "\n",
    "        layer_out = x\n",
    "        for (weight, bias, activation) in self.layers:\n",
    "            if weight is None:\n",
    "                layer_out = activation(layer_out, p=self.keep_prob)\n",
    "            else:\n",
    "                flat_weight = weight.flatten(start_dim=1, end_dim=2)\n",
    "                mixed_weight = torch.matmul(coefficients, flat_weight).view(\n",
    "                    coefficients.shape[0], *weight.shape[1:3]\n",
    "                )\n",
    "\n",
    "                input = layer_out.unsqueeze(1)\n",
    "                mixed_bias = torch.matmul(coefficients, bias).unsqueeze(1)\n",
    "                out = torch.baddbmm(mixed_bias, input, mixed_weight).squeeze(1)\n",
    "                layer_out = activation(out) if activation is not None else out\n",
    "\n",
    "        return layer_out\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        for i, size in enumerate(zip(self.dimensions[0:], self.dimensions[1:])):\n",
    "            if i < len(self.dimensions) - 2:\n",
    "                layers.append(\n",
    "                    (\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[0], size[1])),\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[1])),\n",
    "                        self.act_fn()\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                layers.append(\n",
    "                    (\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[0], size[1])),\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[1])),\n",
    "                        None\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if self.keep_prob > 0:\n",
    "                layers.append((None, None, F.dropout))\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "    def init_params(self):\n",
    "        for i, (w, b, _) in enumerate(self.layers):\n",
    "            if w is None:\n",
    "                continue\n",
    "\n",
    "            i = str(i)\n",
    "            torch.nn.init.kaiming_uniform_(w)\n",
    "            b.data.fill_(0.01)\n",
    "            self.register_parameter(\"w\" + i, w)\n",
    "            self.register_parameter(\"b\" + i, b)\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"dimensions\":self.dimensions,\n",
    "                 \"name\":self.name,\n",
    "                 \"gate\":self.gate.state_dict(), \"phase_input_dim\":self.phase_input_dim,\n",
    "                 \"generationNetwork\":self.state_dict(),\n",
    "                 \"gate_size\":self.gate_size,\n",
    "                 }\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MoE(name=obj[\"name\"], dimensions=obj[\"dimensions\"], gate_size=obj[\"gate_size\"],\n",
    "                    phase_input_dim=obj[\"phase_input_dim\"], load=True)\n",
    "        model.gate.load_state_dict(obj[\"gate\"])\n",
    "        model.load_state_dict(obj[\"generationNetwork\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.99)\n",
    "        return optimizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MotionGenerationModel(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, pose_autoencoder=None, cost_input_dimension=None, phase_dim=0,\n",
    "                 input_slicers:list=None, output_slicers:list=None, train_set=None, val_set=None, name=\"model\", load=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if not load:\n",
    "            self.pose_autoencoder = pose_autoencoder # start with 3\n",
    "            cost_hidden_dim = config[\"cost_hidden_dim\"]\n",
    "            self.cost_encoder = MLP(dimensions=[cost_input_dimension, cost_hidden_dim, cost_hidden_dim],\n",
    "                                    name=\"CostEncoder\", load=True, single_module=-1)\n",
    "\n",
    "\n",
    "            phase_dim = input_slicers[0]\n",
    "            moe_input_dim = pose_autoencoder.dimensions[-1] + cost_hidden_dim\n",
    "            moe_output_dim = pose_autoencoder.dimensions[-1] + pose_autoencoder.extra_feature_len + phase_dim*2\n",
    "            self.generationModel =  MoE(config=config, dimensions=[moe_input_dim, moe_output_dim], phase_input_dim=phase_dim,\n",
    "                                        name=\"MixtureOfExperts\")\n",
    "\n",
    "            self.in_slices = [0] + list(accumulate(add, input_slicers))\n",
    "            self.out_slices = [0] + list(accumulate(add, output_slicers))\n",
    "\n",
    "            self.config=config\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.loss_fn = config[\"loss_fn\"]\n",
    "            self.window_size = config[\"window_size\"]\n",
    "            self.autoregress_prob = config[\"autoregress_prob\"]\n",
    "            self.autoregress_inc = config[\"autoregress_inc\"]\n",
    "            self.best_val_loss = np.inf\n",
    "            self.phase_smooth_factor = 0.9\n",
    "\n",
    "        self.train_set = train_set\n",
    "        self.val_set = val_set\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=torch.squeeze(x,dim=0)\n",
    "        x_tensors = [x[:, d0:d1] for d0, d1 in zip(self.in_slices[:-1], self.in_slices[1:])]\n",
    "        pose_h, pose_label = self.pose_autoencoder.encode(x_tensors[1])\n",
    "        embedding = torch.cat([pose_h, self.cost_encoder(x_tensors[2])], dim=1)\n",
    "\n",
    "        out = self.generationModel(embedding, x_tensors[0])\n",
    "        out_tensors = [out[:, d0:d1] for d0, d1 in zip(self.out_slices[:-1], self.out_slices[1:])] # phase, phase_update, pose\n",
    "\n",
    "        phase = self.update_phase(x_tensors[0], out_tensors[0], out_tensors[1]) # phase_0, phase_1, phase_update\n",
    "        new_pose = self.pose_autoencoder.decode(out_tensors[2], pose_label)\n",
    "        return torch.cat([phase, new_pose], dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "        self.log(\"ptl/val_loss\", loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint()\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir=MODEL_PATH):\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        loss = self.best_val_loss.cpu().numpy()\n",
    "\n",
    "        pose_autoencoder_path = self.pose_autoencoder.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "        cost_encoder_path = self.cost_encoder.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "        generationModel_path = self.generationModel.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "\n",
    "        model = {\"name\":self.name,\n",
    "                 \"pose_autoencoder_path\":pose_autoencoder_path,\n",
    "                 \"cost_encoder_path\": cost_encoder_path,\n",
    "                 \"motionGenerationModelPath\":generationModel_path,\n",
    "                 \"in_slices\":self.in_slices,\n",
    "                 \"out_slices\":self.out_slices,\n",
    "                 }\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        with bz2.BZ2File(os.path.join(path,\n",
    "                                      str(loss)+\".pbz2\"), \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filename, pose_ae_model, cost_encoder_model, generation_model):\n",
    "        with bz2.BZ2File(filename, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        pose_autoencoder = pose_ae_model.load_checkpoint(obj[\"pose_autoencoder_path\"])\n",
    "        cost_encoder = cost_encoder_model.load_checkpoint(obj[\"cost_encoder_path\"])\n",
    "        generationModel = generation_model.load_checkpoint(obj[\"motionGenerationModelPath\"])\n",
    "        model = MotionGenerationModel(name=obj[\"name\"])\n",
    "        model.pose_autoencoder = pose_autoencoder\n",
    "        model.cost_encoder = cost_encoder\n",
    "        model.generationModel = generationModel\n",
    "        model.in_slices = obj[\"in_slices\"]\n",
    "        model.out_slices = obj[\"out_slices\"]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def update_phase(self, p1, p2, p_delta):\n",
    "        return self.phase_smooth_factor * p2 + (1-self.phase_smooth_factor)*(p1+p_delta)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_path = [\"/home/nuoc/Documents/MEX/data/ONE_R2-default-One.pbz2\",\n",
    "             \"/home/nuoc/Documents/MEX/data/ONE_R2-default-One-large.pbz2\",\n",
    "             \"/home/nuoc/Documents/MEX/data/ONE_R2-default-One-small.pbz2\"\n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "pose_features = [\"pos\", \"rotMat\", \"velocity\", \"isLeft\", \"chainPos\", \"geoDistanceNormalised\"]\n",
    "cost_features = [\"posCost\", \"rotCost\", \"targetPosition\", \"targetRotation\",\"contact\"]\n",
    "phase_features = [\"phase_vec\"]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with bz2.BZ2File(file_path, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "        return obj\n",
    "\n",
    "data = [load(path) for path in data_path]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "window = 6\n",
    "data_tensors = []\n",
    "\n",
    "data_dims = []\n",
    "feature_list = []\n",
    "\n",
    "data_nan = []\n",
    "first_row = True\n",
    "for Data in data:\n",
    "    for clip in Data:\n",
    "        d = pickle.loads(clip)\n",
    "        sequence = []\n",
    "        for frame in d[\"frames\"]:\n",
    "            row_vec = []\n",
    "            for feature in phase_features:\n",
    "                if feature == \"phase_vec\":\n",
    "                    sin = np.asarray([jo[\"phase_vec\"] for jo in frame if jo[\"key\"]])\n",
    "                    vel = np.concatenate([jo[\"velocity\"] for jo in frame if jo[\"key\"]])\n",
    "                    vel = np.reshape(vel, (3,-1))\n",
    "                    vel = np.sqrt(np.sum(vel**2, axis=0))\n",
    "                    vel[vel==0] = 1\n",
    "                    cos = np.cos(np.arcsin(sin/vel)) * vel\n",
    "                    row_vec.append(np.concatenate([np.asarray([sin[i], cos[i]]) for i in range(len(sin))]))\n",
    "                else:\n",
    "                    row_vec.append(np.asarray([jo[feature] for jo in frame if jo[\"key\"]]))\n",
    "\n",
    "                if first_row:\n",
    "                    data_dims.append(row_vec[-1].shape)\n",
    "                    feature_list.append(feature)\n",
    "            for feature in pose_features:\n",
    "                if feature==\"rotMat\":\n",
    "                    row_vec.append(np.concatenate([jo[\"rotMat\"].ravel() for jo in frame]))\n",
    "                elif feature == \"isLeft\" or feature == \"chainPos\" or feature == \"geoDistanceNormalised\":\n",
    "                    row_vec.append(np.concatenate([[jo[feature]] for jo in frame]))\n",
    "                else:\n",
    "                    row_vec.append(np.concatenate([jo[feature] for jo in frame]))\n",
    "\n",
    "                if first_row:\n",
    "                    data_dims.append(row_vec[-1].shape)\n",
    "                    feature_list.append(feature)\n",
    "            for feature in cost_features:\n",
    "                if feature == \"contact\":\n",
    "                    row_vec.append(np.asarray([jo[\"contact\"] for jo in frame if jo[\"key\"]], dtype=np.float32))\n",
    "                elif feature == \"targetRotation\":\n",
    "                    row_vec.append(np.concatenate([jo[feature].ravel() for jo in frame if jo[\"key\"]]))\n",
    "                else:\n",
    "                    row_vec.append(np.concatenate([jo[feature] for jo in frame if jo[\"key\"]]))\n",
    "\n",
    "                if first_row:\n",
    "                    data_dims.append(row_vec[-1].shape)\n",
    "                    feature_list.append(feature)\n",
    "            if first_row: first_row = False\n",
    "            sequence.append(np.concatenate(row_vec))\n",
    "            data_nan.append(np.isnan(sequence[-1]))\n",
    "        data_tensors.append(np.vstack(sequence))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    return nn.functional.mse_loss(x,y)\n",
    "def normalise(x):\n",
    "    std = torch.std(x, dim=0)\n",
    "    std[std==0] = 1\n",
    "    return (x-torch.mean(x, dim=0)) / std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  -----  ------  --------  ------  --------  ---------------------  -------  -------  --------------  --------------  -------\n",
      "phase_vec  pos    rotMat  velocity  isLeft  chainPos  geoDistanceNormalised  posCost  rotCost  targetPosition  targetRotation  contact\n",
      "(2,)       (63,)  (189,)  (63,)     (21,)   (21,)     (21,)                  (3,)     (3,)     (3,)            (9,)            (1,)\n",
      "---------  -----  ------  --------  ------  --------  ---------------------  -------  -------  --------------  --------------  -------\n",
      "phase dim:  2\n",
      "pose dim:  378\n",
      "cost dim:  19\n"
     ]
    }
   ],
   "source": [
    "extra_feature_len = 21 * 3\n",
    "n_phase_features = len(phase_features)\n",
    "n_pose_features = len(pose_features)\n",
    "phase_dim = np.sum(data_dims[0:n_phase_features])\n",
    "pose_dim = np.sum(data_dims[n_phase_features:n_phase_features+n_pose_features])\n",
    "cost_dim = np.sum(data_dims[n_phase_features+n_pose_features:])\n",
    "\n",
    "table = [feature_list, data_dims]\n",
    "print(tabulate(table))\n",
    "print(\"phase dim: \",phase_dim)\n",
    "print(\"pose dim: \", pose_dim)\n",
    "print(\"cost dim: \", cost_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "x_tensors = torch.stack([normalise(torch.from_numpy(clip[:-1])).float() for clip in data_tensors])\n",
    "y_tensors = torch.stack([torch.from_numpy(clip[1:][:, :-(cost_dim+extra_feature_len)]).float() for clip in data_tensors])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 torch.Size([119, 399])\n",
      "192 torch.Size([119, 317])\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tensors), x_tensors[0].shape)\n",
    "print(len(y_tensors), y_tensors[0].shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2316, -0.2032,  0.0000,  ...,  0.0000,  0.0000, -0.4001],\n",
      "        [ 0.2313, -0.5907,  0.0000,  ...,  0.0000,  0.0000, -0.4001],\n",
      "        [ 0.2299, -0.6587,  0.0000,  ...,  0.0000,  0.0000, -0.4001],\n",
      "        ...,\n",
      "        [ 0.2327, -0.8959,  0.0000,  ...,  0.0000,  0.0000, -0.4001],\n",
      "        [ 0.2325, -0.8370,  0.0000,  ...,  0.0000,  0.0000, -0.4001],\n",
      "        [ 0.2323, -0.8440,  0.0000,  ...,  0.0000,  0.0000, -0.4001]])\n",
      "torch.return_types.max(\n",
      "values=tensor([[ 0.4351,  8.8726,  0.0000,  ...,  0.0000,  0.0000, -0.3016],\n",
      "        [ 0.4351,  4.2703,  0.0000,  ...,  0.0000,  0.0000, -0.3016],\n",
      "        [ 0.4351,  1.9065,  0.0000,  ...,  0.0000,  0.0000, -0.3016],\n",
      "        ...,\n",
      "        [ 0.4351,  1.2202,  0.0000,  ...,  0.0000,  0.0000, -0.3016],\n",
      "        [ 0.4351,  1.2202,  0.0000,  ...,  0.0000,  0.0000, -0.3016],\n",
      "        [ 0.4351,  1.5600,  0.0000,  ...,  0.0000,  0.0000, -0.3016]]),\n",
      "indices=tensor([[ 76, 191,   0,  ...,   0,   0,  75],\n",
      "        [ 76, 191,   0,  ...,   0,   0,  75],\n",
      "        [ 76, 191,   0,  ...,   0,   0,  75],\n",
      "        ...,\n",
      "        [ 76, 163,   0,  ...,   0,   0,  75],\n",
      "        [ 76, 163,   0,  ...,   0,   0,  75],\n",
      "        [ 76,  11,   0,  ...,   0,   0,  75]]))\n",
      "tensor(0.1824)\n",
      "tensor(7.9523)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(x_tensors, dim=0))\n",
    "print(torch.max(x_tensors, dim=0))\n",
    "print(torch.mean(y_tensors))\n",
    "print(torch.max(y_tensors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 29 29\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(x_tensors, y_tensors)\n",
    "N = len(x_tensors)\n",
    "\n",
    "train_ratio = int(.7*N)\n",
    "val_ratio = int((N-train_ratio) / 2.0)\n",
    "train_set, val_set, test_set = random_split(dataset, [train_ratio, val_ratio, val_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "input_dim = phase_dim + pose_dim + cost_dim\n",
    "output_dim = phase_dim + pose_dim-extra_feature_len\n",
    "print(input_dim)\n",
    "print(output_dim)\n",
    "\n",
    "config = {\n",
    "    \"k_experts\":tune.choice([1, 2, 4, 8, 10]),\n",
    "    \"gate_size\":tune.choice([16, 32, 64, 128]),\n",
    "    \"keep_prob\":tune.choice([.2, .25, .3]),\n",
    "    \"hidden_dim\":tune.choice([16, 32, 64, 128, 256, 512]),\n",
    "    \"cost_hidden_dim\" : tune.choice([16, 32, 64, 128]),\n",
    "    \"batch_size\":tune.choice([1]),\n",
    "    \"lr\":tune.loguniform(1e-5, 1e-7),\n",
    "    \"loss_fn\":tune.choice([loss_fn]),\n",
    "    \"window_size\":tune.choice([1]),\n",
    "    \"autoregress_prob\" : tune.choice([.2]),\n",
    "    \"autoregress_inc\" : tune.choice([.1])\n",
    "}\n",
    "\n",
    "config_2 = {\n",
    "    \"k_experts\": 2,\n",
    "    \"gate_size\": 32,\n",
    "    \"keep_prob\": .3,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"cost_hidden_dim\" : 64,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"loss_fn\": loss_fn,\n",
    "    \"window_size\":1,\n",
    "    \"autoregress_prob\" :.1,\n",
    "    \"autoregress_inc\" :1,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# pose_autoencoder = MLP_withLabel.load_checkpoint(\"/home/nuoc/Documents/MEX/models/MLP4_withLabel_best/M3/0.00324857.512.pbz2\")\n",
    "# pose_encoder_out_dim = pose_autoencoder.dimensions[-1]\n",
    "# input_slices=[phase_dim, pose_dim, cost_dim]\n",
    "# output_slices=[phase_dim, phase_dim, pose_encoder_out_dim]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# model = MotionGenerationModel(config=config_2, pose_autoencoder=pose_autoencoder, cost_input_dimension=cost_dim, phase_dim=phase_dim,\n",
    "#                           input_slicers=input_slices, output_slicers=output_slices,\n",
    "#                           train_set=train_set, val_set=val_set, name=\"Test\")\n",
    "#\n",
    "# optimizer = model.configure_optimizers()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0  Train loss:  0.043551610296230704 Val loss:  0.028038887307047844\n",
      "EPOCH:  1  Train loss:  0.028705251764561703 Val loss:  0.024276675656437874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-82-ef0212f40446>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mavg_train_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_set\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-6d1559c2cf42>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0membedding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpose_h\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcost_encoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_tensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerationModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_tensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0mout_tensors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0md1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md1\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_slices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_slices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m# phase, phase_update, pose\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-5-af636034b80d>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, phase)\u001B[0m\n\u001B[1;32m     37\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m                 \u001B[0mflat_weight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstart_dim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mend_dim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 39\u001B[0;31m                 mixed_weight = torch.matmul(coefficients, flat_weight).view(\n\u001B[0m\u001B[1;32m     40\u001B[0m                     \u001B[0mcoefficients\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m                 )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(20):\n",
    "#     avg_train_loss = 0\n",
    "#     for x, y in train_set:\n",
    "#         out = model(x)\n",
    "#         loss = loss_fn(out, y)\n",
    "#\n",
    "#         avg_train_loss += loss.item()\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         j = 0\n",
    "#         val_loss = 0\n",
    "#         for x,y in val_set:\n",
    "#             out = model(x)\n",
    "#             loss = loss_fn(out, y)\n",
    "#             val_loss += loss\n",
    "#             j+=1\n",
    "#         val_loss /= j\n",
    "#         print(\"EPOCH: \", i, \" Train loss: \", avg_train_loss/len(train_set), \"Val loss: \", val_loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def tuning(config=None, MODEL=None, pose_autoencoder=None, cost_dim=None, phase_dim=None,\n",
    "          input_slices=None, output_slices=None,\n",
    "          train_set=None, val_set=None, num_epochs=300, model_name=\"model\"):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,\n",
    "        gpus=1,\n",
    "        logger=TensorBoardLogger(save_dir=\"logs/\", name=model_name, version=\"0.0\"),\n",
    "        progress_bar_refresh_rate=5,\n",
    "        callbacks=[\n",
    "            TuneReportCallback({\"loss\": \"avg_val_loss\", }, on=\"validation_end\"),\n",
    "            EarlyStopping(monitor=\"avg_val_loss\")\n",
    "        ],\n",
    "        precision=16,\n",
    "    )\n",
    "    model = MODEL(config=config, pose_autoencoder=pose_autoencoder, cost_input_dimension=cost_dim, phase_dim=phase_dim,\n",
    "                              input_slicers=input_slices, output_slicers=output_slices,\n",
    "                              train_set=train_set, val_set=val_set, name=\"Test\")\n",
    "\n",
    "    trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def start_training():\n",
    "    Epochs = 1000\n",
    "    Samples = 50\n",
    "    ModelName=\"Test1-Vanilla\"\n",
    "\n",
    "\n",
    "    pose_autoencoder = MLP_withLabel.load_checkpoint(\"/home/nuoc/Documents/MEX/models/MLP4_withLabel_best/M3/0.00324857.512.pbz2\")\n",
    "\n",
    "\n",
    "    pose_encoder_out_dim = pose_autoencoder.dimensions[-1]\n",
    "    pose_decoder_in_dim = pose_autoencoder.dimensions[-1] + extra_feature_len\n",
    "\n",
    "\n",
    "    scheduler = ASHAScheduler(max_t = Epochs, grace_period=5)\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"k\", \"lr\", \"batch_size\", \"loss_fn\"],\n",
    "        metric_columns=[\"loss\", \"training_iteration\"],\n",
    "        max_error_rows=5,\n",
    "        max_progress_rows=5,\n",
    "        max_report_frequency=10)\n",
    "\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(\n",
    "            tuning,\n",
    "            MODEL=MotionGenerationModel,\n",
    "            pose_autoencoder=pose_autoencoder,\n",
    "            cost_dim = cost_dim,\n",
    "            phase_dim=phase_dim,\n",
    "            input_slices=[phase_dim, pose_dim, cost_dim],\n",
    "            output_slices=[phase_dim, phase_dim, pose_encoder_out_dim],\n",
    "            train_set=train_set, val_set=val_set,\n",
    "            num_epochs=Epochs,\n",
    "            model_name=ModelName\n",
    "        ),\n",
    "        resources_per_trial= {\"cpu\":1, \"gpu\":1},\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        config=config,\n",
    "        num_samples=Samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        name=ModelName,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    print(\"Done\")\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    print(\"Best achieved loss was: \", analysis.best_result)\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    ray.shutdown()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-15 11:29:20,094\tINFO ray_trial_executor.py:197 -- Initializing Ray automatically.For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run`.\n",
      "2021-04-15 11:29:20,768\tINFO services.py:1172 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "start_training()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ray.shutdown()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 4.weight: copying a param with shape torch.Size([4, 32]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for 4.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-23dd72e5f1cf>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m model = MotionGenerationModel.load_checkpoint(filename=\"/home/nuoc/Documents/MEX/models/Test/0.002986041.pbz2\",\n\u001B[0m\u001B[1;32m      2\u001B[0m                                               pose_ae_model=MLP_withLabel, cost_encoder_model=MLP, generation_model=MoE)\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-8-6d1559c2cf42>\u001B[0m in \u001B[0;36mload_checkpoint\u001B[0;34m(filename, pose_ae_model, cost_encoder_model, generation_model)\u001B[0m\n\u001B[1;32m    100\u001B[0m         \u001B[0mpose_autoencoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpose_ae_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"pose_autoencoder_path\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m         \u001B[0mcost_encoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcost_encoder_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"cost_encoder_path\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m         \u001B[0mgenerationModel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgeneration_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"motionGenerationModelPath\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMotionGenerationModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"name\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpose_autoencoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpose_autoencoder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-14-91431608d8b1>\u001B[0m in \u001B[0;36mload_checkpoint\u001B[0;34m(filePath)\u001B[0m\n\u001B[1;32m    115\u001B[0m         model = MoE(name=obj[\"name\"], dimensions=obj[\"dimensions\"], gate_size=obj[\"gate_size\"],\n\u001B[1;32m    116\u001B[0m                     phase_input_dim=obj[\"phase_input_dim\"], load=True)\n\u001B[0;32m--> 117\u001B[0;31m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgate\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"gate\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"generationNetwork\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mload_state_dict\u001B[0;34m(self, state_dict, strict)\u001B[0m\n\u001B[1;32m   1221\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1222\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_msgs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1223\u001B[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001B[0m\u001B[1;32m   1224\u001B[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001B[1;32m   1225\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_IncompatibleKeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmissing_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munexpected_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 4.weight: copying a param with shape torch.Size([4, 32]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for 4.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "model = MotionGenerationModel.load_checkpoint(filename=\"/home/nuoc/Documents/MEX/models/Test/0.002986041.pbz2\",\n",
    "                                              pose_ae_model=MLP_withLabel, cost_encoder_model=MLP, generation_model=MoE)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}