{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, time\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "import json as js\n",
    "import _pickle as pickle\n",
    "import bz2\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from collections import OrderedDict\n",
    "\n",
    "from cytoolz import sliding_window, accumulate, get\n",
    "import pytorch_lightning as pl\n",
    "from operator import add\n",
    "from tabulate import tabulate\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../rig_agnostic_encoding\")\n",
    "sys.path.append(\"../rig_agnostic_encoding/models\")\n",
    "sys.path.append(\"../rig_agnostic_encoding/functions\")\n",
    "import func\n",
    "# from MLP_withLabel import MLP_withLabel\n",
    "# from MLP import MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/nuoc/Documents/MEX/data\"\n",
    "MODEL_PATH = \"/home/nuoc/Documents/MEX/models\"\n",
    "RESULTS_PATH = \"/home/nuoc/Documents/MEX/results\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MLP_withLabel(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, dimensions:list=None, extra_feature_len:int=0,\n",
    "                 train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name:str=\"model\", load=False,\n",
    "                 single_module:int=0):\n",
    "\n",
    "        super(MLP_withLabel, self).__init__()\n",
    "        self.name = name\n",
    "        self.dimensions = dimensions\n",
    "        self.keep_prob = keep_prob\n",
    "        self.single_module = single_module\n",
    "        self.extra_feature_len = extra_feature_len\n",
    "        self.act = nn.ELU\n",
    "        self.k = 0\n",
    "        if load:\n",
    "            self.build()\n",
    "        else:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.k = config[\"k\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.act = config[\"activation\"]\n",
    "            self.loss_fn = config[\"ae_loss_fn\"]\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "            self.dimensions = [self.dimensions[0]-extra_feature_len, self.hidden_dim, self.k]\n",
    "            self.train_set = train_set\n",
    "            self.val_set = val_set\n",
    "            self.test_set = test_set\n",
    "\n",
    "            self.best_val_loss = np.inf\n",
    "\n",
    "        self.build()\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "        if self.single_module == -1 or self.single_module == 0:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.encoder = nn.Sequential()\n",
    "\n",
    "        if self.single_module == 0 or self.single_module == 1:\n",
    "            layers = []\n",
    "            layer_sizes[-1] = (layer_sizes[-1][0], layer_sizes[-1][1] + self.extra_feature_len)\n",
    "            for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decode(*self.encode(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        _x, label = x[:, :-self.extra_feature_len], x[:, -self.extra_feature_len:]\n",
    "        h = self.encoder(_x)\n",
    "        return h, label\n",
    "\n",
    "    def decode(self, h, label):\n",
    "        hr = torch.cat((h, label), dim=1)\n",
    "        return self.decoder(hr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(best_val_loss=self.best_val_loss.cpu().numpy())\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"k\":self.k, \"dimensions\":self.dimensions,\"keep_prob\":self.keep_prob, \"name\":self.name,\n",
    "                 \"extra_feature_len\" : self.extra_feature_len,\n",
    "                 \"encoder\":self.encoder.state_dict(),\n",
    "                 \"decoder\":self.decoder.state_dict()}\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".\"+str(self.k)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MLP_withLabel(name=obj[\"name\"], dimensions=obj[\"dimensions\"], extra_feature_len=obj[\"extra_feature_len\"], keep_prob=obj[\"keep_prob\"], load=True)\n",
    "        model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, dimensions:list=None,\n",
    "                 train_set=None, val_set=None, test_set=None,\n",
    "                 keep_prob:float=.2, name:str=\"model\", load=False,\n",
    "                 single_module:int=0):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        self.name = name\n",
    "        self.dimensions = dimensions\n",
    "        self.keep_prob = keep_prob\n",
    "        self.single_module = single_module\n",
    "        self.act = nn.ELU\n",
    "        self.k = 0\n",
    "        if load:\n",
    "            self.build()\n",
    "        else:\n",
    "            self.hidden_dim = config[\"hidden_dim\"]\n",
    "            self.k = config[\"k\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.act = config[\"activation\"]\n",
    "            self.loss_fn = config[\"loss_fn\"]\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "            self.dimensions = dimensions + [self.hidden_dim, self.k]\n",
    "            self.train_set = train_set\n",
    "            self.val_set = val_set\n",
    "            self.test_set = test_set\n",
    "\n",
    "            self.best_val_loss = np.inf\n",
    "\n",
    "            self.build()\n",
    "        self.encoder.apply(self.init_params)\n",
    "        self.decoder.apply(self.init_params)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        layer_sizes = list(sliding_window(2, self.dimensions))\n",
    "        if self.single_module == -1 or self.single_module == 0:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[0], size[1])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.encoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.encoder = nn.Sequential()\n",
    "\n",
    "        if self.single_module == 0 or self.single_module == 1:\n",
    "            layers = []\n",
    "            for i, size in enumerate(layer_sizes[-1::-1]):\n",
    "                layers.append((\"fc\"+str(i), nn.Linear(size[1], size[0])))\n",
    "                if i < len(self.dimensions)-2:\n",
    "                    layers.append((\"act\"+str(i), self.act()))\n",
    "                    layers.append((\"drop\"+str(i+1), nn.Dropout(self.keep_prob)))\n",
    "            self.decoder = nn.Sequential(OrderedDict(layers))\n",
    "        else:\n",
    "            self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/val_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_fn(prediction, y)\n",
    "\n",
    "        self.log('ptl/test_loss', loss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(best_val_loss=self.best_val_loss.cpu().numpy())\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"k\":self.k, \"dimensions\":self.dimensions,\"keep_prob\":self.keep_prob, \"name\":self.name,\n",
    "                 \"single_module\":self.single_module,\n",
    "                 \"encoder\":self.encoder.state_dict(),\n",
    "                 \"decoder\":self.decoder.state_dict()}\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".\"+str(self.k)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MLP(name=obj[\"name\"], dimensions=obj[\"dimensions\"], keep_prob=obj[\"keep_prob\"],\n",
    "                  load=True)\n",
    "        model.encoder.load_state_dict(obj[\"encoder\"])\n",
    "        # model.decoder.load_state_dict(obj[\"decoder\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def setup_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_params(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MoE(nn.Module):\n",
    "    def __init__(self, config=None, dimensions=None, phase_input_dim:int=0,\n",
    "                 gate_size=0, k_experts=1, keep_prob=.2,\n",
    "                 name=\"model\", load=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.phase_input_dim = phase_input_dim\n",
    "        self.dimensions = dimensions\n",
    "        self.act_fn = nn.ELU\n",
    "        self.name = name\n",
    "        self.config=config\n",
    "        self.gate_size=gate_size\n",
    "        self.k_experts = k_experts\n",
    "        self.keep_prob = .2\n",
    "        if not load:\n",
    "            self.k_experts = config[\"k_experts\"]\n",
    "            self.gate_size = config[\"gate_size\"]\n",
    "            self.keep_prob = config[\"keep_prob\"]\n",
    "            self.dimensions = [self.dimensions[0], config[\"hidden_dim\"], config[\"hidden_dim\"], self.dimensions[-1]]\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        self.build()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(phase_input_dim, self.gate_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.gate_size, self.gate_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.gate_size, self.k_experts)\n",
    "        )\n",
    "        self.init_params()\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor, phase) -> torch.Tensor:\n",
    "        coefficients = F.softmax(self.gate(phase), dim=1)\n",
    "\n",
    "        layer_out = x\n",
    "        for (weight, bias, activation) in self.layers:\n",
    "            if weight is None:\n",
    "                layer_out = activation(layer_out, p=self.keep_prob)\n",
    "            else:\n",
    "                flat_weight = weight.flatten(start_dim=1, end_dim=2)\n",
    "                mixed_weight = torch.matmul(coefficients, flat_weight).view(\n",
    "                    coefficients.shape[0], *weight.shape[1:3]\n",
    "                )\n",
    "\n",
    "                input = layer_out.unsqueeze(1)\n",
    "                mixed_bias = torch.matmul(coefficients, bias).unsqueeze(1)\n",
    "                out = torch.baddbmm(mixed_bias, input, mixed_weight).squeeze(1)\n",
    "                layer_out = activation(out) if activation is not None else out\n",
    "\n",
    "        return layer_out\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        for i, size in enumerate(zip(self.dimensions[0:], self.dimensions[1:])):\n",
    "            if i < len(self.dimensions) - 2:\n",
    "                layers.append(\n",
    "                    (\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[0], size[1])),\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[1])),\n",
    "                        self.act_fn()\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                layers.append(\n",
    "                    (\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[0], size[1])),\n",
    "                        nn.Parameter(torch.empty(self.k_experts, size[1])),\n",
    "                        None\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if self.keep_prob > 0:\n",
    "                layers.append((None, None, F.dropout))\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "    def init_params(self):\n",
    "        for i, (w, b, _) in enumerate(self.layers):\n",
    "            if w is None:\n",
    "                continue\n",
    "\n",
    "            i = str(i)\n",
    "            torch.nn.init.kaiming_uniform_(w)\n",
    "            b.data.fill_(0.01)\n",
    "            self.register_parameter(\"w\" + i, w)\n",
    "            self.register_parameter(\"b\" + i, b)\n",
    "\n",
    "    def save_checkpoint(self, best_val_loss:float=np.inf, checkpoint_dir=MODEL_PATH):\n",
    "\n",
    "        model = {\"dimensions\":self.dimensions,\n",
    "                 \"name\":self.name,\n",
    "                 \"gate\":self.gate.state_dict(), \"phase_input_dim\":self.phase_input_dim,\n",
    "                 \"generationNetwork\":self.state_dict(),\n",
    "                 \"gate_size\":self.gate_size,\n",
    "                 \"k_experts\":self.k_experts,\n",
    "                 }\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.mkdir(checkpoint_dir)\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        filePath = os.path.join(path, str(best_val_loss)+\".pbz2\")\n",
    "        with bz2.BZ2File(filePath, \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        return filePath\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filePath):\n",
    "        with bz2.BZ2File(filePath, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        model = MoE(name=obj[\"name\"], dimensions=obj[\"dimensions\"], gate_size=obj[\"gate_size\"],k_experts=obj[\"k_experts\"],\n",
    "                    phase_input_dim=obj[\"phase_input_dim\"], load=True)\n",
    "        model.gate.load_state_dict(obj[\"gate\"])\n",
    "        model.load_state_dict(obj[\"generationNetwork\"])\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.99)\n",
    "        return optimizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class MotionGenerationModel(pl.LightningModule):\n",
    "    def __init__(self, config:dict=None, pose_autoencoder=None, cost_input_dimension=None, feature_dims=None,\n",
    "                 input_slicers:list=None, output_slicers:list=None, train_set=None, val_set=None, name=\"model\", load=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if not load:\n",
    "            self.pose_autoencoder = pose_autoencoder # start with 3\n",
    "            cost_hidden_dim = config[\"cost_hidden_dim\"]\n",
    "            cost_output_dim = config[\"cost_output_dim\"]\n",
    "            self.cost_encoder = MLP(dimensions=[cost_input_dimension-feature_dims[\"rotCost\"], cost_hidden_dim, cost_hidden_dim, cost_output_dim],\n",
    "                                    name=\"CostEncoder\", load=True, single_module=-1)\n",
    "\n",
    "            self.feature_dims = feature_dims\n",
    "            self.phase_dim = feature_dims[\"phase_vec\"]\n",
    "            self.trajectory_dim = feature_dims[\"tPos\"] + feature_dims[\"tRot\"]\n",
    "            self.cost_dim = trajectory_dim + feature_dims[\"posCost\"]\n",
    "           # phase_input_dimension = input_slicers[0]\n",
    "            moe_input_dim = pose_autoencoder.dimensions[-1] + cost_output_dim\n",
    "            moe_output_dim = pose_autoencoder.dimensions[-1] +  self.phase_dim + self.trajectory_dim\n",
    "            self.generationModel =  MoE(config=config, dimensions=[moe_input_dim, moe_output_dim], phase_input_dim=self.phase_dim + feature_dims[\"posCost\"],\n",
    "                                        name=\"MixtureOfExperts\")\n",
    "\n",
    "            self.in_slices = [0] + list(accumulate(add, input_slicers))\n",
    "            self.out_slices = [0] + list(accumulate(add, output_slicers))\n",
    "            # self.phase_dim = phase_dim\n",
    "\n",
    "            self.config=config\n",
    "            self.batch_size = config[\"batch_size\"]\n",
    "            self.learning_rate = config[\"lr\"]\n",
    "            self.loss_fn = config[\"loss_fn\"]\n",
    "            self.window_size = config[\"window_size\"]\n",
    "            self.autoregress_chunk_size = config[\"autoregress_chunk_size\"]\n",
    "            self.autoregress_prob = config[\"autoregress_prob\"]\n",
    "            self.autoregress_inc = config[\"autoregress_inc\"]\n",
    "            self.best_val_loss = np.inf\n",
    "            self.phase_smooth_factor = 0.9\n",
    "\n",
    "        self.train_set = train_set\n",
    "        self.val_set = val_set\n",
    "        self.name = name\n",
    "        self.epochs = 0\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_tensors = [x[:, d0:d1] for d0, d1 in zip(self.in_slices[:-1], self.in_slices[1:])]\n",
    "        pose_h, pose_label = self.pose_autoencoder.encode(x_tensors[1])\n",
    "        phase = x_tensors[0][:, :self.phase_dim]\n",
    "        targets = x_tensors[0][:, self.phase_dim:]\n",
    "        embedding = torch.cat([pose_h, self.cost_encoder(x_tensors[2][:, :self.cost_dim])], dim=1)\n",
    "        # embedding = torch.cat([pose_h)], dim=1)\n",
    "        # embedding = torch.cat([pose_h, x_tensors[2]], dim=1)\n",
    "        posCost, rotCost = self.computeCost(targets, x_tensors[-1])\n",
    "        out = self.generationModel(embedding, torch.cat([phase, posCost], dim=1))\n",
    "        out_tensors = [out[:, d0:d1] for d0, d1 in zip(self.out_slices[:-1], self.out_slices[1:])] # phase, phase_update, pose\n",
    "        phase = self.update_phase(phase, out_tensors[0]) # phase_0, phase_1, phase_update\n",
    "        new_pose = self.pose_autoencoder.decode(out_tensors[1], pose_label)\n",
    "\n",
    "        posCost, rotCost = self.computeCost(targets, out_tensors[-1])\n",
    "        # print(phase.size(), targets.size(), new_pose.size(), pose_label.size(), out_tensors[-1].size(), posCost.size(), rotCost.size())\n",
    "        # return [phase, targets, new_pose, pose_label, out_tensors[-1], posCost, rotCost]\n",
    "        return [phase, targets, new_pose, pose_label, out_tensors[-1], posCost]\n",
    "        # return [phase, targets, new_pose, pose_label, out_tensors[-1]]\n",
    "\n",
    "    def computeCost(self, targets, trajectory):\n",
    "        targetPos = targets[:, :self.feature_dims[\"targetPosition\"]]\n",
    "        # targetRot = targets[:, self.feature_dims[\"targetPosition\"]:]\n",
    "        posT = trajectory[:, :self.feature_dims[\"tPos\"]]\n",
    "        # rotT = trajectory[:, self.feature_dims[\"tPos\"]:]\n",
    "\n",
    "        targetPos = targetPos.reshape((-1, 1, 3))\n",
    "        posT = posT.reshape((-1, 24, 3))\n",
    "        # targetRot = targetRot.reshape((-1, 12, 3,3))\n",
    "        # rotT = rotT.reshape((-1, 12, 3, 3))\n",
    "\n",
    "        posCost = torch.sum(((targetPos - posT)**2), axis=2).reshape((-1, self.feature_dims[\"posCost\"]))\n",
    "        # colLength = torch.sqrt(torch.clip(torch.sum(rotT**2, axis=2), 0))\n",
    "        # rotT = rotT / colLength[:, :, :, None]\n",
    "\n",
    "        # rotT = torch.transpose(rotT, dim0=2, dim1=3)\n",
    "        # trace =torch.diagonal(targetRot @ rotT, offset=0, dim1=2, dim2=3).sum(dim=2)\n",
    "        # rotCost = torch.abs(torch.arccos((torch.clamp( (trace - 1) / 2.0, -1, 1))))\n",
    "        # torch.nan_to_num_(rotCost, 0)\n",
    "        # rotCost = rotCost.reshape((-1, self.feature_dims[\"rotCost\"]))\n",
    "\n",
    "        return posCost, 0\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, x, y, validation=False):\n",
    "        if not validation:\n",
    "           opt = self.optimizers()\n",
    "        x = x.squeeze(dim=2)\n",
    "        y = y.squeeze(dim=2)\n",
    "\n",
    "        n = x.size()[1]\n",
    "        tot_loss = 0\n",
    "        tot_posLoss = 0\n",
    "        tot_rotLoss = 0\n",
    "        x_c = x[:,0,:]\n",
    "\n",
    "        if self.autoregress_prob < 1:\n",
    "            autoregress_bools = torch.randn(n) < self.autoregress_prob\n",
    "            for i in range(1, n):\n",
    "                y_c = y[:,i-1,:]\n",
    "                # y_c.requires_grad_(True)\n",
    "\n",
    "\n",
    "                out= self(x_c)\n",
    "                recon = torch.cat((out[0], out[2], out[4]), dim=1)\n",
    "                loss = self.loss_fn(recon, y_c)\n",
    "                posLoss = torch.mean(out[5])\n",
    "                # rotLoss = torch.mean(out[-1])\n",
    "                # rotLoss = 0\n",
    "                #\n",
    "                tot_loss += loss.detach()\n",
    "                tot_posLoss += posLoss.detach()\n",
    "                # tot_rotLoss += rotLoss.detach()\n",
    "                tot_rotLoss += 0\n",
    "\n",
    "                # elif not recon.requires_grad:\n",
    "                #     raise ValueError(\"recon no grad, i : \", i, \" \\n\", recon, y_c)\n",
    "                # elif not loss.requires_grad:\n",
    "                #     raise ValueError(\"loss no grad\")\n",
    "                if not validation:\n",
    "                    opt.zero_grad()\n",
    "                    # self.optimizer.zero_grad()\n",
    "                    self.manual_backward(loss+posLoss)\n",
    "                    # self.optimizer.step()\n",
    "                    opt.step()\n",
    "\n",
    "                if self.autoregress_prob > 0 and autoregress_bools[i]:\n",
    "                    x_c = torch.cat(out,dim=1).detach()\n",
    "                else:\n",
    "                    x_c = x[:,i,:]\n",
    "\n",
    "            tot_loss /= float(i+1)\n",
    "            tot_posLoss /= float(i+1)\n",
    "            tot_rotLoss /= float(i+1)\n",
    "        else:\n",
    "            for i in range(1, n):\n",
    "                y_c = y[:,i-1,:]\n",
    "\n",
    "\n",
    "                out= self(x_c)\n",
    "                recon = torch.cat((out[0], out[2], out[4]), dim=1)\n",
    "                loss = self.loss_fn(recon, y_c)\n",
    "                # posLoss = torch.mean(out[-2])\n",
    "                posLoss = torch.mean(out[5])\n",
    "                # rotLoss = torch.mean(out[-1])\n",
    "                # rotLoss = 0\n",
    "\n",
    "                tot_loss += loss.detach()\n",
    "                tot_posLoss = posLoss.detach()\n",
    "                # tot_rotLoss += rotLoss.detach()\n",
    "                tot_rotLoss += 0\n",
    "                # self.optimizer.zero_grad()\n",
    "                # (loss + posLoss + rotLoss).backward()\n",
    "                if not validation:\n",
    "                    opt.zero_grad()\n",
    "                    # self.optimizer.zero_grad()\n",
    "                    self.manual_backward(loss+posLoss)\n",
    "                    # self.optimizer.step()\n",
    "                    opt.step()\n",
    "\n",
    "                x_c = torch.cat(out, dim=1).detach()\n",
    "\n",
    "            tot_loss /= float(i+1)\n",
    "            tot_posLoss /= float(i+1)\n",
    "            tot_rotLoss /= float(i+1)\n",
    "\n",
    "        return tot_loss, tot_posLoss, tot_rotLoss\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss, posLoss, rotLoss = self.step(x,y, False)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"ptl/train_posLoss\", posLoss)\n",
    "        self.log(\"ptl/train_rotLoss\", rotLoss)\n",
    "        # return loss#+posLoss+rotLoss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss, posLoss, rotLoss = self.step(x,y, True)\n",
    "        self.log(\"ptl/val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"ptl/val_posLoss\", posLoss, prog_bar=True)\n",
    "        self.log(\"ptl/val_rotLoss\", rotLoss, prog_bar=True)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if self.epochs > 0 and self.epochs % 10==0:\n",
    "            self.autoregress_prob = min(1, self.autoregress_prob+self.autoregress_inc)\n",
    "            self.autoregress_chunk_size = min(120, self.autoregress_chunk_size+self.autoregress_inc)\n",
    "        elif self.epochs > 0 and self.epochs % 10==0:\n",
    "            self.scheduler.step()\n",
    "        self.epochs += 1\n",
    "\n",
    "\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint()\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir=MODEL_PATH):\n",
    "        path = os.path.join(checkpoint_dir, self.name)\n",
    "        loss = self.best_val_loss.cpu().numpy()\n",
    "\n",
    "        pose_autoencoder_path = self.pose_autoencoder.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "        cost_encoder_path = self.cost_encoder.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "        generationModel_path = self.generationModel.save_checkpoint(best_val_loss=loss, checkpoint_dir=path)\n",
    "\n",
    "        model = {\"name\":self.name,\n",
    "                 \"pose_autoencoder_path\":pose_autoencoder_path,\n",
    "                 \"cost_encoder_path\": cost_encoder_path,\n",
    "                 \"motionGenerationModelPath\":generationModel_path,\n",
    "                 \"in_slices\":self.in_slices,\n",
    "                 \"out_slices\":self.out_slices,\n",
    "                 }\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        with bz2.BZ2File(os.path.join(path,\n",
    "                                      str(loss)+\".pbz2\"), \"w\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filename, pose_ae_model, cost_encoder_model, generation_model):\n",
    "        with bz2.BZ2File(filename, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "\n",
    "        pose_autoencoder = pose_ae_model.load_checkpoint(obj[\"pose_autoencoder_path\"])\n",
    "        cost_encoder = cost_encoder_model.load_checkpoint(obj[\"cost_encoder_path\"])\n",
    "        generationModel = generation_model.load_checkpoint(obj[\"motionGenerationModelPath\"])\n",
    "        model = MotionGenerationModel(name=obj[\"name\"])\n",
    "        model.pose_autoencoder = pose_autoencoder\n",
    "        model.cost_encoder = cost_encoder\n",
    "        model.generationModel = generationModel\n",
    "        model.in_slices = obj[\"in_slices\"]\n",
    "        model.out_slices = obj[\"out_slices\"]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def update_phase(self, p1, p2):\n",
    "        return self.phase_smooth_factor * p2 + (1-self.phase_smooth_factor)*p1\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "        self.scheduler = scheduler\n",
    "        self.optimizer = optimizer\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_path = [\n",
    "             \"/home/nuoc/Documents/MEX/data/TWO_R2-default-Two.pbz2\",\n",
    "            # \"/home/nuoc/Documents/MEX/data/ONE_R2-default-One.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/ONE_R2-default-One-large.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/ONE_R2-default-One-small.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/TWO_R2-default-Two-small.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/TWO_R2-default-Two-large.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/TWO_ROT_R2-default-Two.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/TWO_ROT_R2-default-Two-large.pbz2\",\n",
    "            #  \"/home/nuoc/Documents/MEX/data/TWO_ROT_R2-default-Two-small.pbz2\",\n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# pose_features = [\"pos\", \"rotMat\", \"velocity\", \"isLeft\", \"chainPos\", \"geoDistanceNormalised\"]\n",
    "# cost_features = [\"tPos\", \"tRot\", \"posCost\", \"rotCost\"]\n",
    "# phase_features = [\"phase_vec\", \"targetPosition\", \"targetRotation\"]\n",
    "\n",
    "pose_features = [\"pos\", \"rotMat\", \"velocity\", \"isLeft\", \"chainPos\", \"geoDistanceNormalised\"]\n",
    "cost_features = [\"tPos\", \"tRot\", \"posCost\", \"rotCost\"]\n",
    "phase_features = [\"phase_vec\", \"targetPosition\", \"targetRotation\"]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with bz2.BZ2File(file_path, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "        return obj\n",
    "\n",
    "data = [load(path) for path in data_path]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "frame_window = 30\n",
    "sampling_step = frame_window / window_size\n",
    "\n",
    "data_tensors = []\n",
    "\n",
    "data_dims = []\n",
    "feature_list = []\n",
    "\n",
    "first_row = True\n",
    "first_time = True\n",
    "key_joints = []\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "for Data in data:\n",
    "    for clip in Data:\n",
    "        d = pickle.loads(clip)\n",
    "        sequence = []\n",
    "        n_frames = len(d[\"frames\"])\n",
    "        if first_time:\n",
    "            key_joints = [i for i in range(len(d[\"frames\"][0])) if d[\"frames\"][0][i][\"key\"]]\n",
    "            first_time = False\n",
    "        for f, frame in enumerate(d[\"frames\"]):\n",
    "            row_vec = []\n",
    "            f_idx = np.arange(f-frame_window, f+frame_window, sampling_step, dtype=int)\n",
    "            f_idx[f_idx < 0] = 0\n",
    "            f_idx[f_idx >= n_frames] = n_frames-1\n",
    "            f_idx = f_idx.tolist()\n",
    "            for feature in phase_features:\n",
    "                if feature == \"phase_vec\":\n",
    "                    sin = np.asarray([d[\"frames\"][idx][jj][\"phase_vec\"] for jj in key_joints for idx in f_idx])\n",
    "                    vel = np.concatenate([d[\"frames\"][idx][jj][\"velocity\"] for jj in key_joints for idx in f_idx])\n",
    "                    vel = np.reshape(vel, (3,-1))\n",
    "                    vel = np.sqrt(np.sum(vel**2, axis=0))\n",
    "                    cos = np.cos(np.arcsin(np.asarray([d[\"frames\"][idx][jj][\"sin_normalised_contact\"] for jj in key_joints for idx in f_idx])))\n",
    "                    cos = cos * vel\n",
    "                    row_vec.append(np.concatenate([np.asarray([sin[i], cos[i]]) for i in range(len(sin))]))\n",
    "                elif feature == \"targetRotation\":\n",
    "                    row_vec.append(np.concatenate([frame[jj][feature].ravel() for jj in key_joints]))\n",
    "                elif feature == \"contact\":\n",
    "                    row_vec.append(np.asarray([d[\"frames\"][idx][jj][\"contact\"] for jj in key_joints for idx in f_idx]))\n",
    "                else:\n",
    "                    row_vec.append(np.concatenate([frame[jj][feature] for jj in key_joints]))\n",
    "\n",
    "                if first_row:\n",
    "                    data_dims.append(row_vec[-1].shape)\n",
    "                    feature_list.append(feature)\n",
    "\n",
    "            for feature in pose_features:\n",
    "                if feature==\"rotMat\":\n",
    "                    row_vec.append(np.concatenate([jo[\"rotMat\"].ravel() for jo in frame]))\n",
    "                elif feature == \"isLeft\" or feature == \"chainPos\" or feature == \"geoDistanceNormalised\":\n",
    "                    row_vec.append(np.concatenate([[jo[feature]] for jo in frame]))\n",
    "                else:\n",
    "                    row_vec.append(np.concatenate([jo[feature] for jo in frame]))\n",
    "\n",
    "                if first_row:\n",
    "                    data_dims.append(row_vec[-1].shape)\n",
    "                    feature_list.append(feature)\n",
    "            for feature in cost_features:\n",
    "                if feature == \"posCost\" or feature == \"rotCost\":\n",
    "                    row_vec.append(np.concatenate([d[\"frames\"][idx][jj][feature] for jj in key_joints for idx in f_idx]))\n",
    "                elif feature == \"tPos\" or feature == \"tRot\":\n",
    "                    feature = \"pos\" if feature == \"tPos\" else \"rotMat\"\n",
    "                    row_vec.append(np.concatenate([d[\"frames\"][idx][jj][feature].ravel() for jj in key_joints for idx in f_idx]))\n",
    "                else:\n",
    "                    row_vec.append(np.concatenate([frame[jj][feature] for jj in key_joints]))\n",
    "\n",
    "                if first_row:\n",
    "                    data_dims.append(row_vec[-1].shape)\n",
    "                    feature_list.append(feature)\n",
    "            if first_row: first_row = False\n",
    "            sequence.append(np.concatenate(row_vec))\n",
    "        data_tensors.append(np.vstack(sequence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    return nn.functional.mse_loss(x,y)\n",
    "def loss_fn2(x, y):\n",
    "    return nn.functional.smooth_l1_loss(x,y)\n",
    "def normalise(x):\n",
    "    std = torch.std(x, dim=0)\n",
    "    std[std==0] = 1\n",
    "    return (x-torch.mean(x, dim=0)) / std\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  --------------  --------------  -----  ------  --------  ------  --------  ---------------------  -----  ------  -------  -------\n",
      "phase_vec  targetPosition  targetRotation  pos    rotMat  velocity  isLeft  chainPos  geoDistanceNormalised  pos    rotMat  posCost  rotCost\n",
      "(48,)      (6,)            (18,)           (63,)  (189,)  (63,)     (21,)   (21,)     (21,)                  (72,)  (216,)  (72,)    (72,)\n",
      "---------  --------------  --------------  -----  ------  --------  ------  --------  ---------------------  -----  ------  -------  -------\n",
      "phase dim:  72\n",
      "pose dim:  378\n",
      "cost dim:  432\n"
     ]
    }
   ],
   "source": [
    "extra_feature_len = 21 * 3\n",
    "n_phase_features = len(phase_features)\n",
    "n_pose_features = len(pose_features)\n",
    "phase_dim = np.sum(data_dims[0:n_phase_features])\n",
    "pp_dim = data_dims[0][0]\n",
    "pose_dim = np.sum(data_dims[n_phase_features:n_phase_features+n_pose_features])\n",
    "cost_dim = np.sum(data_dims[n_phase_features+n_pose_features:])\n",
    "\n",
    "table = [feature_list, data_dims]\n",
    "print(tabulate(table))\n",
    "print(\"phase dim: \",phase_dim)\n",
    "print(\"pose dim: \", pose_dim)\n",
    "print(\"cost dim: \", cost_dim)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# x_tensors = torch.nn.utils.rnn.pad_sequence([normalise(torch.from_numpy(clip[:-1])).float().unsqueeze(dim=1) for clip in data_tensors], batch_first=True)\n",
    "# y_tensors = torch.nn.utils.rnn.pad_sequence([normalise(torch.from_numpy(clip[1:])).float().unsqueeze(dim=1) for clip in data_tensors], batch_first=True)\n",
    "x_tensors = torch.stack([normalise(torch.from_numpy(clip[:-1])).float() for clip in data_tensors])\n",
    "y_tensors = torch.stack([torch.from_numpy(clip[1:]).float() for clip in data_tensors])\n",
    "y_tensors2 = torch.stack([normalise(torch.from_numpy(clip[1:])).float() for clip in data_tensors])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 10 10\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(torch.Tensor(x_tensors), torch.Tensor(y_tensors2))\n",
    "N = len(x_tensors)\n",
    "\n",
    "train_ratio = int(.7*N)\n",
    "val_ratio = int((N-train_ratio) / 2.0)\n",
    "test_ratio = N - train_ratio - val_ratio\n",
    "train_set, val_set, test_set = random_split(dataset, [train_ratio, val_ratio, test_ratio], generator=torch.Generator().manual_seed(2021))\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_1 = {\"data_sets\":[train_set, val_set, test_set], \"table\":table}\n",
    "with bz2.BZ2File(\"data_sets_7_terminateAtContact_cost.pbz2\", \"w\") as f:\n",
    "    pickle.dump(data_1, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# with bz2.BZ2File(\"data_sets_7_terminateAtContact_cost.pbz2\", \"rb\") as f:\n",
    "#     obj = pickle.load(f)\n",
    "#\n",
    "# train_set = obj[\"data_sets\"][0]\n",
    "# val_set = obj[\"data_sets\"][1]\n",
    "# test_set = obj[\"data_sets\"][2]\n",
    "# table = obj[\"table\"]\n",
    "feature_dims = {}\n",
    "for feat, dim in zip(table[0], table[1]):\n",
    "    if feat in feature_dims:\n",
    "        if feat == \"pos\": feat = \"tPos\"\n",
    "        elif feat == \"rotMat\": feat = \"tRot\"\n",
    "    feature_dims[feat] = dim[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"k_experts\": 4,\n",
    "    \"gate_size\": 64,\n",
    "    \"keep_prob\": 0.3,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"cost_hidden_dim\" : 256,\n",
    "    \"cost_output_dim\" : 256,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 1e-4,\n",
    "    \"loss_fn\": loss_fn,\n",
    "    \"window_size\":1,\n",
    "    \"autoregress_prob\" : 0,\n",
    "    \"autoregress_inc\" : .2,\n",
    "    \"autoregress_chunk_size\": 120\n",
    "}\n",
    "\n",
    "model_name = \"Test_22_phase+pose+cost+trajectory_autoregress_prob_tearcher_forced_fullset\"\n",
    "epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "phase_dim = sum([feature_dims[feat] for feat in phase_features])\n",
    "pose_dim = sum([feature_dims[feat] for feat in pose_features])\n",
    "cost_dim = sum([feature_dims[feat] for feat in cost_features])\n",
    "trajectory_dim = feature_dims[\"tPos\"] + feature_dims[\"tRot\"]\n",
    "\n",
    "pose_autoencoder = MLP_withLabel.load_checkpoint(\"/home/nuoc/Documents/MEX/models/MLP4_withLabel_best/M3/0.00324857.512.pbz2\")\n",
    "pose_encoder_out_dim = pose_autoencoder.dimensions[-1]\n",
    "\n",
    "input_slices=[phase_dim, pose_dim, cost_dim]\n",
    "output_slices=[feature_dims[\"phase_vec\"], pose_encoder_out_dim, trajectory_dim]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def reformLabel(dataset, slices, phase_dim, extra_feature_len, trajectory_dim):\n",
    "    set_y = list(dataset[:][1])\n",
    "    slices = [0] + list(accumulate(add, slices))\n",
    "    for i, y in enumerate(set_y):\n",
    "        y = y.squeeze(1)\n",
    "        y_tensors = [y[:, d0:d1] for d0, d1 in zip(slices[:-1], slices[1:])]\n",
    "        phase = y_tensors[0][:, :phase_dim]\n",
    "        pose = y_tensors[1][:, :-extra_feature_len]\n",
    "        trajectory = y_tensors[2][:, :trajectory_dim]\n",
    "        set_y[i] = torch.cat([phase, pose, trajectory], dim=1).unsqueeze(dim=1)\n",
    "    return [(x, y) for x, y in zip(dataset[:][0], set_y)]\n",
    "\n",
    "train_set = reformLabel(train_set, slices=input_slices, phase_dim=feature_dims[\"phase_vec\"], extra_feature_len=21*3, trajectory_dim=trajectory_dim)\n",
    "val_set = reformLabel(val_set, slices=input_slices, phase_dim=feature_dims[\"phase_vec\"], extra_feature_len=21*3, trajectory_dim=trajectory_dim)\n",
    "test_set = reformLabel(test_set, slices=input_slices, phase_dim=feature_dims[\"phase_vec\"], extra_feature_len=21*3, trajectory_dim=trajectory_dim)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model = MotionGenerationModel(config=config, pose_autoencoder=pose_autoencoder, cost_input_dimension=cost_dim,\n",
    "                          input_slicers=input_slices, output_slicers=output_slices,feature_dims=feature_dims,\n",
    "                          train_set=train_set, val_set=val_set, name=model_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | pose_autoencoder | MLP_withLabel | 440 K \n",
      "1 | cost_encoder     | MLP           | 224 K \n",
      "2 | generationModel  | MoE           | 4.4 M \n",
      "---------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.171    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbb45b6f2da94ebba5189adf65b1c60e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-831648a238a1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0mtrain_loader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"batch_size\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpin_memory\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0mval_loader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"batch_size\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpin_memory\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    498\u001B[0m         \u001B[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 499\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m         \u001B[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mdispatch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    544\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    545\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 546\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    547\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    548\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain_or_test_or_predict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001B[0m in \u001B[0;36mstart_training\u001B[0;34m(self, trainer)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_testing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001B[0m in \u001B[0;36mstart_training\u001B[0;34m(self, trainer)\u001B[0m\n\u001B[1;32m    112\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Trainer'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0;31m# double dispatch to initiate the training loop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstart_testing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Trainer'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mrun_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    605\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprogress_bar_callback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 607\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_sanity_check\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlightning_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    608\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    609\u001B[0m         \u001B[0;31m# set stage for logging\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mrun_sanity_check\u001B[0;34m(self, ref_model)\u001B[0m\n\u001B[1;32m    854\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    855\u001B[0m             \u001B[0;31m# run eval step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 856\u001B[0;31m             \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_batches\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_sanity_val_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    857\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    858\u001B[0m             \u001B[0;31m# allow no returns from eval\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001B[0m in \u001B[0;36mrun_evaluation\u001B[0;34m(self, max_batches, on_epoch)\u001B[0m\n\u001B[1;32m    723\u001B[0m                 \u001B[0;31m# lightning module methods\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"evaluation_step_and_end\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 725\u001B[0;31m                     \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluation_loop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluation_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataloader_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    726\u001B[0m                     \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluation_loop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluation_step_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001B[0m in \u001B[0;36mevaluation_step\u001B[0;34m(self, batch, batch_idx, dataloader_idx)\u001B[0m\n\u001B[1;32m    162\u001B[0m             \u001B[0mmodel_ref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_current_fx_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"validation_step\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    163\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"validation_step\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 164\u001B[0;31m                 \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidation_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    165\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    166\u001B[0m         \u001B[0;31m# capture any logged information\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001B[0m in \u001B[0;36mvalidation_step\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    175\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprecision_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mval_step_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mval_step_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 177\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_type_plugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidation_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    178\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtest_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001B[0m in \u001B[0;36mvalidation_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mvalidation_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 131\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlightning_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidation_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtest_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-62e528988609>\u001B[0m in \u001B[0;36mvalidation_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m    185\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mposLoss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrotLoss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ptl/val_loss\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprog_bar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ptl/val_posLoss\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mposLoss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprog_bar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-62e528988609>\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, x, y, validation)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 110\u001B[0;31m                 \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_c\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    111\u001B[0m                 \u001B[0mrecon\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_c\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-62e528988609>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[0;31m# embedding = torch.cat([pose_h)], dim=1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;31m# embedding = torch.cat([pose_h, x_tensors[2]], dim=1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mposCost\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrotCost\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcomputeCost\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtargets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_tensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerationModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mphase\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mposCost\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mout_tensors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0md1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md1\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_slices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_slices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m# phase, phase_update, pose\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-62e528988609>\u001B[0m in \u001B[0;36mcomputeCost\u001B[0;34m(self, targets, trajectory)\u001B[0m\n\u001B[1;32m     75\u001B[0m         \u001B[0;31m# rotT = rotT.reshape((-1, 12, 3, 3))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 77\u001B[0;31m         \u001B[0mposCost\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtargetPos\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mposT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature_dims\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"posCost\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     78\u001B[0m         \u001B[0;31m# colLength = torch.sqrt(torch.clip(torch.sum(rotT**2, axis=2), 0))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0;31m# rotT = rotT / colLength[:, :, :, None]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "# prob\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"avg_val_loss\", save_top_k=3)\n",
    "# earlystopping = EarlyStopping(monitor=\"avg_val_loss\", patience=20)\n",
    "logger=TensorBoardLogger(save_dir=\"logs/\", name=model_name, version=\"0.0\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"/home/nuoc/Documents/MEX/src/motion_generation/checkpoints\",\n",
    "    gpus=1, precision=16,\n",
    "    # callbacks=[checkpoint_callback],\n",
    "    logger=logger,\n",
    "    min_epochs=50,\n",
    "    max_epochs=epochs,\n",
    "    stochastic_weight_avg=True\n",
    ")\n",
    "\n",
    "# train_set = datasets[0][0]\n",
    "# val_set = datasets[0][1]\n",
    "train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], pin_memory=True, num_workers=6)\n",
    "val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"], pin_memory=True, num_workers=6)\n",
    "trainer.fit(model,train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type          | Params\n",
      "---------------------------------------------------\n",
      "0 | pose_autoencoder | MLP_withLabel | 440 K \n",
      "1 | cost_encoder     | MLP           | 171 K \n",
      "2 | generationModel  | MoE           | 8.1 M \n",
      "---------------------------------------------------\n",
      "8.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 M     Total params\n",
      "34.707    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a207ed1306a4db69f47908e1de899d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7cae70884b243718ba01f4c014defc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuoc/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model,train_loader, val_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    with bz2.BZ2File(path, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "        return obj\n",
    "mo = load(\"/home/nuoc/Documents/MEX/src/motion_generation/Test_8_phase+pose+cost+trajectory_autoregress_prob_curriculum/0.11878604.pbz2\")\n",
    "ae = load(mo[\"pose_autoencoder_path\"])\n",
    "cost = load(mo[\"cost_encoder_path\"])\n",
    "gene = load(mo[\"motionGenerationModelPath\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pose_autoencoder.encoder.load_state_dict(ae[\"encoder\"])\n",
    "model.pose_autoencoder.decoder.load_state_dict(ae[\"decoder\"])\n",
    "model.cost_encoder.encoder.load_state_dict(cost[\"encoder\"])\n",
    "model.generationModel.gate.load_state_dict(gene[\"gate\"])\n",
    "model.generationModel.load_state_dict(gene[\"generationNetwork\"])\n",
    "\n",
    "# pose_autoencoder = pose_ae_model.load_checkpoint(mo[\"pose_autoencoder_path\"])\n",
    "# cost_encoder = cost_encoder_model.load_checkpoint(obj[\"cost_encoder_path\"])\n",
    "# generationModel = generation_model.load_checkpoint(obj[\"motionGenerationModelPath\"])\n",
    "# model.save_checkpoint(\"\")\n",
    "# model = MotionGenerationModel.load_checkpoint(\n",
    "#     filename=\",\n",
    "# pose_ae_model=MLP_withLabel, cost_encoder_model=MLP, generation_model=MoE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model.autoregress_prob = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09795486181974411\n",
      "0.0009730978636071086\n"
     ]
    }
   ],
   "source": [
    "# test_set2 = reformLabel(test_set, slices=input_slices, phase_dim=feature_dims[\"phase_vec\"], extra_feature_len=21*3, trajectory_dim=trajectory_dim)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=config[\"batch_size\"], pin_memory=True, num_workers=6)\n",
    "model.cpu()\n",
    "with torch.no_grad():\n",
    "    loss, posLoss = 0, 0\n",
    "    for x,y in test_loader:\n",
    "        x = x.to(\"cpu\")\n",
    "        y = y.to(\"cpu\")\n",
    "        l, pll, rl = model.step(x, y, validation=True)\n",
    "        loss += l\n",
    "        posLoss += pll\n",
    "    loss /= float(len(test_loader))\n",
    "    posLoss /= float(len(test_loader))\n",
    "    print(loss.item())\n",
    "    print(posLoss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}